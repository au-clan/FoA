{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook\n",
    "This is a testing notebook, serving no other purpose other than testing things out while developping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "from src.models import OpenAIBot\n",
    "from src.prompts.game24 import foa_step_prompt, value_prompt, value_last_step_prompt, bfs_prompt\n",
    "from src.tasks.base import DATA_PATH\n",
    "from src.tasks.game24 import Game24\n",
    "from src.methods.agents import Agents\n",
    "from src.methods.resampler import Resampler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "bot = OpenAIBot(model=\"gpt-3.5-turbo-1106\")\n",
    "#bot = OpenAIBot(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt testing\n",
    "from src.prompts.game24 import foa_step_prompt, value_prompt, value_last_step_prompt, bfs_prompt, cot_prompt\n",
    "x = 20\n",
    "input = \"1 24\"\n",
    "\n",
    "prompt = foa_step_prompt.format(input=input) \n",
    "\n",
    "for i in range(x):\n",
    "    response = bot.request(prompt)\n",
    "\n",
    "print(f\"Prompt \\n{prompt}\")\n",
    "print(\"----\\n----\\n\")\n",
    "print(f\"Response \\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game24 task step function\n",
    "\n",
    "task = Game24(bot)\n",
    "idx = randint(0, len(task))\n",
    "task.get_input(idx)\n",
    "\n",
    "\n",
    "value_numbers = []\n",
    "for i in range(task.max_steps):\n",
    "    task.step()\n",
    "    value_number = task.evaluate()\n",
    "    value_numbers.append(value_number)\n",
    "summary = []\n",
    "\n",
    "for i in range(len(task.steps)):\n",
    "    temp = task.steps[i] + f\" [Value : {value_numbers[i]}]\"\n",
    "    summary.append(temp)\n",
    "\n",
    "print(f\"Input: {task.input}\")\n",
    "print(\"\\n\".join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampler\n",
    "\n",
    "values = np.array([20, 10, 5, 1, 0.0001])\n",
    "resampler = Resampler()\n",
    "\n",
    "# Normalized resampling\n",
    "draw = resampler.resample(values, resample_method=\"normalization\")\n",
    "print(f\"Normalized : {draw}\")\n",
    "\n",
    "\n",
    "# Greedy\n",
    "draw = resampler.resample(values, resample_method=\"greedy\")\n",
    "print(f\"Greedy : {draw}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple agents\n",
    "\n",
    "idx_input = 8\n",
    "n_evaluations = 2\n",
    "n_agents = 2\n",
    "\n",
    "# Create agents\n",
    "agents = Agents(task=Game24, idx_input=idx_input, n_agents=n_agents, init=False, model=bot, n_evaluations=2)\n",
    "\n",
    "# Run agents\n",
    "for i in range(agents.max_steps-1):\n",
    "    agents.step()\n",
    "    agents.evaluate()\n",
    "    agents.resample()\n",
    "\n",
    "# Final step : Finish answers format + Choose best answer\n",
    "agents.step() \n",
    "\n",
    "# Log results\n",
    "current_path = os.getcwd()\n",
    "log_path = os.path.join(os.path.dirname(current_path), \"logs\")\n",
    "agents.create_log(repo_path=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test results funciton\n",
    "\n",
    "idx_input = 8\n",
    "n_evaluations = 3\n",
    "n_agents = 5\n",
    "\n",
    "# Create agents\n",
    "agents = Agents(task=Game24, idx_input=idx_input, n_agents=n_agents, model=bot)\n",
    "\n",
    "# Run agents\n",
    "for i in range(agents.max_steps-1):\n",
    "    agents.step()\n",
    "    agents.evaluate(n=n_evaluations)\n",
    "    agents.resample()\n",
    "\n",
    "# Final step : Finish answers format + Choose best answer\n",
    "agents.step() \n",
    "\n",
    "print(\"\\n\\n\".join([\"\\n\".join(agent.steps) for agent in agents.agents]))\n",
    "print(f\"\\nResults : {agents.test_output()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "# set up logging\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from diskcache import Cache\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# TODO: Not sure if this is correct, I didn't know how else to handle the package paths\n",
    "import sys\n",
    "sys.path.append(os.getcwd()) # Project root!!\n",
    "\n",
    "from async_engine.cached_api import CachedOpenAIAPI\n",
    "from async_engine.round_robin_manager import AsyncRoundRobin\n",
    "from async_implementation.agents.gameof24 import GameOf24Agent\n",
    "from async_implementation.states.gameof24 import GameOf24State\n",
    "from utils import create_folder, email_notification\n",
    "from async_engine.mock_batched_async import BatchingAPI\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling methods\n",
    "\n",
    "values = [0, 0.001, 0.003, 1, 3, 20, 60]\n",
    "\n",
    "print(f\"Linear probabilities : {[round(p, 3) for p in linear(values)]}\")\n",
    "print(f\"Logistic probabilities : {[round(p, 3) for p in logistic(values)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gameof24State Hash\n",
    "\n",
    "path = 'data/24_tot.csv'\n",
    "data = pd.read_csv(path).Puzzles.tolist()\n",
    "\n",
    "puzzle_idx = 0\n",
    "puzzle = data[puzzle_idx]\n",
    "\n",
    "num_agents = 1\n",
    "\n",
    "s1 = GameOf24State(puzzle=puzzle, current_state=puzzle, steps=[], randomness=random.randint(0, 1000))\n",
    "s2 = GameOf24State(puzzle=puzzle, current_state=puzzle, steps=[], randomness=random.randint(0, 1000))\n",
    "s3 = GameOf24State(puzzle=puzzle, current_state=puzzle, steps=[\"something\"], randomness=random.randint(0, 1000))\n",
    "s4 = GameOf24State(puzzle=puzzle, current_state=\"24\", steps=[\"something\"], randomness=random.randint(0, 1000))\n",
    "\n",
    "# Randomness does not count towards the hash function\n",
    "hash(s1), hash(s2), hash(s3), hash(s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bactched API\n",
    "\n",
    "# Cache setup\n",
    "assert os.path.exists(\n",
    "    \"./caches/\"), \"Please run the script from the root directory of the project. To make sure all caches are created correctly.\"\n",
    "cache = Cache(\"./caches/async_api_cache\", size_limit=int(2e10))\n",
    "\n",
    "# OpenAI API key setup\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "assert OPENAI_API_KEY is not None, \"Please set the OPENAI_API_KEY environment variable\"\n",
    "\n",
    "# API setup\n",
    "api_config = {\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"request_timeout\": 45,\n",
    "    \"model\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "api = CachedOpenAIAPI(cache, api_config)\n",
    "\n",
    "# Limiter setup\n",
    "limiter = AsyncRoundRobin()\n",
    "N = 4\n",
    "for _ in range(N):\n",
    "    limiter.add_resource(data=OPENAI_API_KEY)\n",
    "\n",
    "prompt = \"What is the capital of France?\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "#response = await api.uncached_request(messages, limiter, n=1)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Setup batching API\n",
    "batch_size = 2\n",
    "bapi = BatchingAPI(batch_size, api, limiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bapi.immediate_request(messages, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Futures : {bapi.futures}\")\n",
    "print(f\"Prompts : {bapi.prompts}\")\n",
    "print(f\"Batches processed : {bapi.num_batches_processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    prompt: str\n",
    "\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    @staticmethod\n",
    "    async def step(state: State, api: BatchingAPI):\n",
    "        # make request\n",
    "        result = await api.buffered_request(state.prompt)\n",
    "\n",
    "        # do something with the result\n",
    "        # ...\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crosswords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to the JSON file\n",
    "file_path = \"data/datasets/mini0505.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "class MiniCrosswordsEnv:\n",
    "    def __init__(self, file='mini0505.json'):\n",
    "        self.file = os.path.join(\"data\", 'datasets', file)\n",
    "\n",
    "        self.file = json.load(open(self.file))\n",
    "        self.n = len(self.file)\n",
    "        self.cache = {}\n",
    "        self.idx = None\n",
    "        self.times = 0\n",
    "        self.prompt_status_cache = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def reset(self, idx, board=None, status=None, steps=None):\n",
    "        self.idx = idx\n",
    "        self.data, self.board_gt = self.file[idx]\n",
    "        self.board = ['_'] * 25\n",
    "        self.ans = ['_____'] * 10\n",
    "        self.ans_gt = self.get_ans(self.board_gt)\n",
    "        self.steps = 0\n",
    "        self.status = [0] * 10  # 0: unfilled; 1: filled; 2: filled then changed\n",
    "        if board is not None:\n",
    "            self.board = board\n",
    "            self.ans = self.get_ans(self.board)\n",
    "        if status is not None:\n",
    "            self.status = status\n",
    "        if steps is not None:\n",
    "            self.steps = steps\n",
    "        return self.render()\n",
    "\n",
    "    def prompt_status(self):\n",
    "        count = {'sure': 0, 'maybe': 0, 'impossible': 0}\n",
    "        for ans, data, status in zip(self.ans, self.data, self.status):\n",
    "            # if status != 0: continue\n",
    "            if ans.count('_') >= 4: \n",
    "                continue\n",
    "            ans = ' '.join(ans.lower())\n",
    "            line = f'{data}: {ans}'\n",
    "            prompt = value_prompt.format(input=line)\n",
    "            if prompt in self.prompt_status_cache:\n",
    "                res = self.prompt_status_cache[prompt]\n",
    "            else:\n",
    "                res = gpt(prompt)[0]\n",
    "                self.prompt_status_cache[prompt] = res\n",
    "            # print(line)\n",
    "            # print(res)\n",
    "            # print()\n",
    "            res = res.split('\\n')[-1].strip()\n",
    "            if res in count: count[res] += 1\n",
    "        # print(count)\n",
    "        return count\n",
    "\n",
    "    def get_ans(self, board: List[str])-> List[str]:\n",
    "        \"\"\"\"\n",
    "        Given the board, return the answers.\n",
    "\n",
    "        Example\n",
    "            board: ['A', 'G', 'E', 'N', 'D', 'M', 'O', 'T', 'O', 'R', 'A', 'R', 'T', 'S', 'Y', 'S', 'A', 'L', 'L', 'E', 'S', 'L', 'E', 'E', 'R']\n",
    "            ans: ['AGEND', 'MOTOR', 'ARTSY', 'SALLE', 'SLEER', 'AMASS', 'GORAL', 'ETTLE', 'NOSLE', 'DRYER']\n",
    "        \"\"\"\n",
    "        ans = [''] * 10\n",
    "        for i in range(5):\n",
    "            ans[i] = ''.join(board[i*5:(i+1)*5])\n",
    "        for i in range(5):\n",
    "            ans[i+5] = ''.join(board[i::5])\n",
    "        return ans\n",
    "\n",
    "    def render_gt_board(self)-> str:\n",
    "        \"\"\"\n",
    "        Renders the ground truth board.\n",
    "\n",
    "        Example\n",
    "            self.board_gt: ['A', 'G', 'E', 'N', 'D', 'M', 'O', 'T', 'O', 'R', 'A', 'R', 'T', 'S', 'Y', 'S', 'A', 'L', 'L', 'E', 'S', 'L', 'E', 'E', 'R']\n",
    "            return: GT Board:\n",
    "                    A G E N D\n",
    "                    M O T O R\n",
    "                    A R T S Y\n",
    "                    S A L L E\n",
    "                    S L E E R\n",
    "        \"\"\"\n",
    "        s = \"GT Board:\\n\"\n",
    "        for i in range(5):\n",
    "            s += ' '.join(self.board_gt[i*5:(i+1)*5]) + '\\n'\n",
    "        return s\n",
    "    \n",
    "    def render_board(self)-> str:\n",
    "        \"\"\"\n",
    "        Renders the current board.\n",
    "\n",
    "        Exactly same function as render_gt_board() but applied to self.board (current board) instead of self.board_gt (ground truth board).\n",
    "        \"\"\"\n",
    "        s = \"Current Board:\\n\"\n",
    "        for i in range(5):\n",
    "            s += ''.join(self.board[i*5:(i+1)*5]) + '\\n'\n",
    "        return s\n",
    "    \n",
    "    def render_clues(self, status=None)-> str:\n",
    "        \"\"\"\n",
    "        Renders the clued/data. If status is not None, only render the clued/data with the given status.\n",
    "\n",
    "        Example (first 3)\n",
    "            self.data: ['An agendum; something to be done', 'An engine', 'Pretentious; flowery']\n",
    "            return: h1. An agendum; something to be done\n",
    "                    h2. An engine\n",
    "                    h3. Pretentious; flowery\n",
    "        \"\"\"\n",
    "        s = \"\"\n",
    "        # s += \"Horizontal:\\n\"\n",
    "        for i in range(5):\n",
    "            if status is None or self.status[i] == status:\n",
    "                s += 'h' + str(i+1) + '. ' + self.data[i] + '\\n'\n",
    "        # s += \"Vertical:\\n\"\n",
    "        for i in range(5, 10):\n",
    "            if status is None or self.status[i] == status:\n",
    "                s += 'v' + str(i-5+1) + '. ' + self.data[i] + '\\n'\n",
    "        return s\n",
    "    \n",
    "    def render_gt_ans(self, status=None)-> str:\n",
    "        \"\"\"\n",
    "        Renders the ground truth answers. If status is not None, only render the answers with the given status.\n",
    "\n",
    "        Example (first 3)\n",
    "            self.data: ['An agendum; something to be done', 'An engine', 'Pretentious; flowery']\n",
    "            self.ans_gt: ['AGEND','MOTOR','ARTSY']\n",
    "            return: h1. An agendum; something to be done: AGEND\n",
    "                    h2. An engine: MOTOR\n",
    "                    h3. Pretentious; flowery: ARTSY\n",
    "        \"\"\"\n",
    "        s = \"\"\n",
    "        # s += \"Horizontal:\\n\"\n",
    "        for i in range(5):\n",
    "            if status is None or self.status[i] == status:\n",
    "                s += 'h' + str(i+1) + '. ' + self.data[i] + ': ' + self.ans_gt[i] + '\\n'\n",
    "        # s += \"Vertical:\\n\"\n",
    "        for i in range(5, 10):\n",
    "            if status is None or self.status[i] == status:\n",
    "                s += 'v' + str(i-5+1) + '. ' + self.data[i] + ': ' + self.ans_gt[i] + '\\n'\n",
    "        return s\n",
    "    \n",
    "    def render_ans(self, status=None):\n",
    "        \"\"\"\n",
    "        Renders the current answers. If status is not None, only render the answers with the given status.\n",
    "\n",
    "        Exactly same function as render_gt_ans() but applied to self.ans (current answers) instead of self.ans_gt (ground truth answers).\n",
    "        \"\"\"\n",
    "        s = \"\"\n",
    "        # s += \"Horizontal:\\n\"\n",
    "        for i in range(5):\n",
    "            if status is None or self.status[i] == status:\n",
    "                s += 'h' + str(i+1) + '. ' + self.data[i] + ': ' + self.ans[i] + '\\n'\n",
    "        # s += \"Vertical:\\n\"\n",
    "        for i in range(5, 10):\n",
    "            if status is None or self.status[i] == status:\n",
    "                s += 'v' + str(i-5+1) + '. ' + self.data[i] + ': ' + self.ans[i] + '\\n'\n",
    "        return s\n",
    "    \n",
    "    def render(self, status=True):\n",
    "        if status:\n",
    "            return self.render_board() + '\\nUnfilled:\\n' + self.render_ans(status=0) + '\\nFilled:\\n' + self.render_ans(status=1) + '\\nChanged:\\n' + self.render_ans(status=2)\n",
    "        else:\n",
    "            return self.render_board() + '\\n' + self.render_ans()\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.steps += 1\n",
    "        action = action.split('\\n')[-1]\n",
    "        action = action.split('. ')\n",
    "        if len(action) != 2:\n",
    "            return 'Invalid! Format should be like \"h1. apple\"', 0, False, {}\n",
    "        pos, word = action\n",
    "\n",
    "        if len(word) != 5:\n",
    "            return 'Invalid! Word should have 5 letters.', 0, False, {}\n",
    "        if pos.startswith('h'):\n",
    "            idx = int(pos[1:]) - 1\n",
    "            self.board[idx*5:(idx+1)*5] = list(word.upper())\n",
    "        elif pos.startswith('v'):\n",
    "            idx = int(pos[1:]) - 1\n",
    "            self.board[idx::5] = list(word.upper())\n",
    "            idx += 5  # for later status update\n",
    "        else:\n",
    "            return 'Invalid! Position should be h1-h5 or v1-v5', 0, False, {}\n",
    "        \n",
    "        self.new_ans = self.get_ans(self.board)\n",
    "        # self.status = [2 if (status == 1 and ans != new_ans) else status for status, ans, new_ans in zip(self.status, self.ans, self.new_ans)]\n",
    "        self.status = [2 if any(letter != new_letter and letter != '_' for letter, new_letter in zip(ans, new_ans)) else status for status, ans, new_ans in zip(self.status, self.ans, self.new_ans)]\n",
    "        self.status[idx] = 1\n",
    "        self.ans = self.new_ans\n",
    "        r_all = (self.board == self.board_gt)\n",
    "        r_letter = sum(a == b for a, b in zip(self.board, self.board_gt)) / 25\n",
    "        r_word = sum(a == b for a, b in zip(self.ans, self.ans_gt)) / 10\n",
    "        return self.render(), r_all, (r_all or self.steps >= 20), {'r_letter': r_letter, 'r_word': r_word, 'r_game': r_all}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from async_implementation.prompts.crosswords import propose_prompt, value_prompt\n",
    "import re\n",
    "import asyncio\n",
    "\n",
    "def prompt_wrap(obs):\n",
    "    return propose_prompt.format(input=obs)\n",
    "\n",
    "def parse_line(input_str):\n",
    "    # regular expression pattern to match the input string format\n",
    "    pattern = r'^([hv][1-5])\\. ([a-zA-Z]{5,5}) \\((certain|high|medium|low)\\).*$'\n",
    "\n",
    "    # use regex to extract the parts of the input string\n",
    "    match = re.match(pattern, input_str)\n",
    "\n",
    "    if match:\n",
    "        # extract the matched groups\n",
    "        parts = [match.group(1), match.group(2), match.group(3)]\n",
    "        return parts\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def parse_response(response):\n",
    "\n",
    "    # map confidence levels to values\n",
    "    confidence_to_value = {'certain': 1, 'high': 0.5, 'medium': 0.2, 'low': 0.1}  # TODO: ad hoc\n",
    "\n",
    "    # split the response into lines\n",
    "    lines = response.split('\\n')\n",
    "\n",
    "    # parse each line\n",
    "    parsed_lines = [parse_line(line) for line in lines]\n",
    "\n",
    "    # filter out the lines that didn't match the format\n",
    "    parsed_lines = [(line[0].lower() + '. ' + line[1].lower(), confidence_to_value.get(line[2], 0)) for line in parsed_lines if line is not None]\n",
    "\n",
    "    return parsed_lines if len(parsed_lines) >= 1 else None\n",
    "\n",
    "async def get_candidates_to_scores(env, api, n=8):\n",
    "    obs = env.render()\n",
    "    if obs in env.cache: \n",
    "        print('cache hit')\n",
    "        return env.cache[obs]\n",
    "    print('call gpt')\n",
    "    \n",
    "    coroutines = []\n",
    "    for _ in range(n):\n",
    "        coroutines.append(api.buffered_request(prompt_wrap(obs)))\n",
    "    responses = await asyncio.gather(*coroutines)\n",
    "    candidates_to_scores = {}\n",
    "    for response in responses:\n",
    "        parsed_response = parse_response(response)\n",
    "        if parsed_response:\n",
    "            for candidate, score in parsed_response:\n",
    "                candidates_to_scores[candidate] = candidates_to_scores.get(candidate, 0) + score\n",
    "        # choose candiate with highest score\n",
    "    # print(sorted(candidates_to_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "    env.cache[obs] = candidates_to_scores\n",
    "    return candidates_to_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from async_engine.cached_api import CachedOpenAIAPI\n",
    "from async_engine.round_robin_manager import AsyncRoundRobin\n",
    "from async_engine.mock_batched_async import BatchingAPI\n",
    "from diskcache import Cache\n",
    "\n",
    "assert os.path.exists(\n",
    "    \"./caches/\"), \"Please run the script from the root directory of the project. To make sure all caches are created correctly.\"\n",
    "cache = Cache(\"./caches/async_api_cache\", size_limit=int(2e10))\n",
    "\n",
    "# get OPENAI_API_KEY from env\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "assert OPENAI_API_KEY is not None, \"Please set the OPENAI_API_KEY environment variable\"\n",
    "\n",
    "api_config = {\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"request_timeout\": 45,\n",
    "    \"model\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "\n",
    "api = CachedOpenAIAPI(cache, api_config)\n",
    "limiter = AsyncRoundRobin()\n",
    "# ToDo, this is a bit hacky. OpenAI allows multiple parallel requests per key, so we add the same key multiple times\n",
    "N = 4\n",
    "for _ in range(N):\n",
    "    limiter.add_resource(data=OPENAI_API_KEY)\n",
    "\n",
    "api = BatchingAPI(api, limiter, batch_size=2, timeout=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MiniCrosswordsEnv()\n",
    "env.reset(0)\n",
    "\n",
    "candidates_to_scores = await get_candidates_to_scores(env, api, n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(candidates_to_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "board, status, steps = env.board.copy(), env.status.copy(), env.steps\n",
    "\n",
    "print(f\"board : {board}\")\n",
    "print(f\"status : {status}\")\n",
    "print(f\"steps : {steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in sorted(candidates_to_scores, key=candidates_to_scores.get, reverse=True):\n",
    "    print(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = \"h2. motor\"\n",
    "obs, r, done, info = env.step(action)\n",
    "\n",
    "print(f\"obs : {obs}\")\n",
    "print(f\"r : {r}\")\n",
    "print(f\"done : {done}\")\n",
    "print(f\"info : {info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step\n",
    "\n",
    "board = ['_'] * 25\n",
    "print(f\"Board : {board}\")\n",
    "\n",
    "action = \"h2. motor\"\n",
    "print(f\"Action : '{action}'\")\n",
    "\n",
    "action = action.split('\\n')[-1]\n",
    "print(f\"Action : '{action}'\")\n",
    "\n",
    "action = action.split('. ')\n",
    "print(f\"Action : '{action}'\")\n",
    "\n",
    "pos, word = action\n",
    "print(f\"Pos : '{pos}'\")\n",
    "print(f\"Word : '{word}'\")\n",
    "\n",
    "if pos.startswith('h'):\n",
    "    idx = int(pos[1:]) - 1\n",
    "    board[idx*5:(idx+1)*5] = list(word.upper())\n",
    "print(f\"Board : {board}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm keeping the same comments, etc everywhere, so that later it's easier to merge experiments.gameof24.py and experiments.crosswords.py (hydra?)\n",
    "\n",
    "import asyncio\n",
    "# set up logging\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from diskcache import Cache\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# TODO: Not sure if this is correct, I didn't know how else to handle the package paths\n",
    "import sys\n",
    "sys.path.append(os.getcwd()) # Project root!!\n",
    "\n",
    "from async_engine.cached_api import CachedOpenAIAPI\n",
    "from async_engine.round_robin_manager import AsyncRoundRobin\n",
    "from async_engine.batched_api import BatchingAPI\n",
    "from async_implementation.agents.crosswords import CrosswordsAgent\n",
    "from async_implementation.states.crosswords import CrosswordsState\n",
    "from utils import create_folder, email_notification\n",
    "\n",
    "logger = logging.getLogger(\"experiments\")\n",
    "logger.setLevel(logging.DEBUG) # Order : debug < info < warning < error < critical\n",
    "log_folder = f\"logs/{datetime.now().date()}/{datetime.now().strftime('%H')}:00/\" # Folder in which logs will be saved (organized daily)\n",
    "create_folder(log_folder)\n",
    "\n",
    "# you should use the same cache for every instance of CachedOpenAIAPI\n",
    "# that way we never pay for the same request twice\n",
    "assert os.path.exists(\n",
    "    \"./caches/\"), \"Please run the script from the root directory of the project. To make sure all caches are created correctly.\"\n",
    "cache = Cache(\"./caches/async_api_cache\", size_limit=int(2e10))\n",
    "\n",
    "# get OPENAI_API_KEY from env\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "assert OPENAI_API_KEY is not None, \"Please set the OPENAI_API_KEY environment variable\"\n",
    "\n",
    "api_config = {\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"request_timeout\": 45,\n",
    "    \"model\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "\n",
    "api = CachedOpenAIAPI(cache, api_config)\n",
    "limiter = AsyncRoundRobin()\n",
    "# ToDo, this is a bit hacky. OpenAI allows multiple parallel requests per key, so we add the same key multiple times\n",
    "N = 4\n",
    "for _ in range(N):\n",
    "    limiter.add_resource(data=OPENAI_API_KEY)\n",
    "\n",
    "# Set up Crosswords puzzles\n",
    "path = \"data/datasets/mini0505.json\"\n",
    "with open(path, \"r\") as file:\n",
    "    dataset = json.load(file)\n",
    "\n",
    "# ToDo: this should probably be moved to its own file\n",
    "# for now I'm keeping it here, for easier debugging\n",
    "#async def foa_gameof24(puzzle_idx: int, num_agents=3, k=2, backtrack=0.8):\n",
    "async def foa_crosswords(puzzle_idx, foa_options):\n",
    "    randomness = 0\n",
    "    random.seed(randomness)\n",
    "\n",
    "    data, board_gt = dataset[puzzle_idx] # Data is the list of clues, board_gt is the ground truth  board\n",
    "    ans_gt = CrosswordsState.get_ans(board_gt) # Get the ground truth answers\n",
    "\n",
    "    # Set up states\n",
    "    states = []\n",
    "    for _ in range(foa_options[\"num_agents\"]):\n",
    "        states.append(CrosswordsState(data=data, board_gt=board_gt, ans_gt=ans_gt, randomness=random.randint(0, 1000)))\n",
    "\n",
    "    num_steps = foa_options[\"num_steps\"]\n",
    "    for step in range(num_steps):\n",
    "        print(f\"Step {step}\")\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "puzzle_idx = 1\n",
    "data, board_gt = dataset[puzzle_idx] \n",
    "ans_gt = CrosswordsState.get_ans(board_gt)\n",
    "\n",
    "state = CrosswordsState(data=data, board_gt=board_gt, ans_gt=ans_gt, randomness=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "# set up logging\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from diskcache import Cache\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# TODO: Not sure if this is correct, I didn't know how else to handle the package paths\n",
    "import sys\n",
    "sys.path.append(os.getcwd()) # Project root!!\n",
    "\n",
    "from async_engine.cached_api import CachedOpenAIAPI\n",
    "from async_engine.round_robin_manager import AsyncRoundRobin\n",
    "from async_engine.batched_api import BatchingAPI\n",
    "from async_implementation.agents.gameof24 import GameOf24Agent\n",
    "from async_implementation.states.gameof24 import GameOf24State\n",
    "from utils import create_folder, email_notification\n",
    "\n",
    "logger = logging.getLogger(\"experiments\")\n",
    "logger.setLevel(logging.DEBUG) # Order : debug < info < warning < error < critical\n",
    "log_folder = f\"logs/{datetime.now().date()}/{datetime.now().strftime('%H')}:00/gameof24\" # Folder in which logs will be saved (organized daily)\n",
    "create_folder(log_folder)\n",
    "\n",
    "\n",
    "# you should use the same cache for every instance of CachedOpenAIAPI\n",
    "# that way we never pay for the same request twice\n",
    "assert os.path.exists(\n",
    "    \"./caches/\"), \"Please run the script from the root directory of the project. To make sure all caches are created correctly.\"\n",
    "cache = Cache(\"./caches/async_api_cache\", size_limit=int(2e10))\n",
    "\n",
    "# get OPENAI_API_KEY from env\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "assert OPENAI_API_KEY is not None, \"Please set the OPENAI_API_KEY environment variable\"\n",
    "\n",
    "api_config = {\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"request_timeout\": 45,\n",
    "    \"model\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "\n",
    "api = CachedOpenAIAPI(cache, api_config)\n",
    "limiter = AsyncRoundRobin()\n",
    "# ToDo, this is a bit hacky. OpenAI allows multiple parallel requests per key, so we add the same key multiple times\n",
    "N = 4\n",
    "for _ in range(N):\n",
    "    limiter.add_resource(data=OPENAI_API_KEY)\n",
    "\n",
    "# set up GameOf24 puzzles\n",
    "path = 'data/datasets/24_tot.csv'\n",
    "data = pd.read_csv(path).Puzzles.tolist()\n",
    "\n",
    "# Use batching API\n",
    "api = BatchingAPI(api, limiter, batch_size=1, timeout=10)\n",
    "\n",
    "# Data\n",
    "path = 'data/datasets/24_tot.csv'\n",
    "data = pd.read_csv(path).Puzzles.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle_idx = 0\n",
    "puzzle = data[puzzle_idx]\n",
    "state = GameOf24State(puzzle=puzzle, current_state=puzzle, steps=[], randomness=random.randint(0, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 1 4 6'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state = await GameOf24Agent.step(state, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 2 6'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state.current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '1', '4', '6']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expression(state):\n",
    "    states = state.current_state.split(\" \")\n",
    "    return states\n",
    "\n",
    "function(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[1, 2, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "my_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Pop the last element from the list\n",
    "last_element = my_list.pop()\n",
    "print(last_element)  # Output: 5\n",
    "print(my_list)  # Output: [1, 2, 3, 4]\n",
    "\n",
    "# Pop the element at index 2 from the list\n",
    "element_at_index_2 = my_list.pop(2)\n",
    "print(element_at_index_2)  # Output: 3\n",
    "print(my_list)  # Output: [1, 2, 4]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
