{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook\n",
    "This is a testing notebook, serving no other purpose other than testing things out while developping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "from src.models import OpenAIBot\n",
    "from src.prompts.game24 import foa_step_prompt, value_prompt, value_last_step_prompt, bfs_prompt\n",
    "from src.tasks.base import DATA_PATH\n",
    "from src.tasks.game24 import Game24\n",
    "from src.methods.agents import Agents\n",
    "from src.methods.resampler import Resampler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "bot = OpenAIBot(model=\"gpt-3.5-turbo-1106\")\n",
    "#bot = OpenAIBot(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt testing\n",
    "from src.prompts.game24 import foa_step_prompt, value_prompt, value_last_step_prompt, bfs_prompt, cot_prompt\n",
    "x = 20\n",
    "input = \"1 24\"\n",
    "\n",
    "prompt = foa_step_prompt.format(input=input) \n",
    "\n",
    "for i in range(x):\n",
    "    response = bot.request(prompt)\n",
    "\n",
    "print(f\"Prompt \\n{prompt}\")\n",
    "print(\"----\\n----\\n\")\n",
    "print(f\"Response \\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game24 task step function\n",
    "\n",
    "task = Game24(bot)\n",
    "idx = randint(0, len(task))\n",
    "task.get_input(idx)\n",
    "\n",
    "\n",
    "value_numbers = []\n",
    "for i in range(task.max_steps):\n",
    "    task.step()\n",
    "    value_number = task.evaluate()\n",
    "    value_numbers.append(value_number)\n",
    "summary = []\n",
    "\n",
    "for i in range(len(task.steps)):\n",
    "    temp = task.steps[i] + f\" [Value : {value_numbers[i]}]\"\n",
    "    summary.append(temp)\n",
    "\n",
    "print(f\"Input: {task.input}\")\n",
    "print(\"\\n\".join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampler\n",
    "\n",
    "values = np.array([20, 10, 5, 1, 0.0001])\n",
    "resampler = Resampler()\n",
    "\n",
    "# Normalized resampling\n",
    "draw = resampler.resample(values, resample_method=\"normalization\")\n",
    "print(f\"Normalized : {draw}\")\n",
    "\n",
    "\n",
    "# Greedy\n",
    "draw = resampler.resample(values, resample_method=\"greedy\")\n",
    "print(f\"Greedy : {draw}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple agents\n",
    "\n",
    "idx_input = 8\n",
    "n_evaluations = 2\n",
    "n_agents = 2\n",
    "\n",
    "# Create agents\n",
    "agents = Agents(task=Game24, idx_input=idx_input, n_agents=n_agents, init=False, model=bot, n_evaluations=2)\n",
    "\n",
    "# Run agents\n",
    "for i in range(agents.max_steps-1):\n",
    "    agents.step()\n",
    "    agents.evaluate()\n",
    "    agents.resample()\n",
    "\n",
    "# Final step : Finish answers format + Choose best answer\n",
    "agents.step() \n",
    "\n",
    "# Log results\n",
    "current_path = os.getcwd()\n",
    "log_path = os.path.join(os.path.dirname(current_path), \"logs\")\n",
    "agents.create_log(repo_path=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test results funciton\n",
    "\n",
    "idx_input = 8\n",
    "n_evaluations = 3\n",
    "n_agents = 5\n",
    "\n",
    "# Create agents\n",
    "agents = Agents(task=Game24, idx_input=idx_input, n_agents=n_agents, model=bot)\n",
    "\n",
    "# Run agents\n",
    "for i in range(agents.max_steps-1):\n",
    "    agents.step()\n",
    "    agents.evaluate(n=n_evaluations)\n",
    "    agents.resample()\n",
    "\n",
    "# Final step : Finish answers format + Choose best answer\n",
    "agents.step() \n",
    "\n",
    "print(\"\\n\\n\".join([\"\\n\".join(agent.steps) for agent in agents.agents]))\n",
    "print(f\"\\nResults : {agents.test_output()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "# set up logging\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from diskcache import Cache\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# TODO: Not sure if this is correct, I didn't know how else to handle the package paths\n",
    "import sys\n",
    "sys.path.append(os.getcwd()) # Project root!!\n",
    "\n",
    "from async_engine.cached_api import CachedOpenAIAPI\n",
    "from async_engine.round_robin_manager import AsyncRoundRobin\n",
    "from async_implementation.agents.gameof24 import GameOf24Agent\n",
    "from async_implementation.states.gameof24 import GameOf24State\n",
    "from utils import create_folder, email_notification\n",
    "from async_engine.mock_batched_async import BatchingAPI\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling methods\n",
    "\n",
    "values = [0, 0.001, 0.003, 1, 3, 20, 60]\n",
    "\n",
    "print(f\"Linear probabilities : {[round(p, 3) for p in linear(values)]}\")\n",
    "print(f\"Logistic probabilities : {[round(p, 3) for p in logistic(values)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gameof24State Hash\n",
    "\n",
    "path = 'data/24_tot.csv'\n",
    "data = pd.read_csv(path).Puzzles.tolist()\n",
    "\n",
    "puzzle_idx = 0\n",
    "puzzle = data[puzzle_idx]\n",
    "\n",
    "num_agents = 1\n",
    "\n",
    "s1 = GameOf24State(puzzle=puzzle, current_state=puzzle, steps=[], randomness=random.randint(0, 1000))\n",
    "s2 = GameOf24State(puzzle=puzzle, current_state=puzzle, steps=[], randomness=random.randint(0, 1000))\n",
    "s3 = GameOf24State(puzzle=puzzle, current_state=puzzle, steps=[\"something\"], randomness=random.randint(0, 1000))\n",
    "s4 = GameOf24State(puzzle=puzzle, current_state=\"24\", steps=[\"something\"], randomness=random.randint(0, 1000))\n",
    "\n",
    "# Randomness does not count towards the hash function\n",
    "hash(s1), hash(s2), hash(s3), hash(s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bactched API\n",
    "\n",
    "# Cache setup\n",
    "assert os.path.exists(\n",
    "    \"./caches/\"), \"Please run the script from the root directory of the project. To make sure all caches are created correctly.\"\n",
    "cache = Cache(\"./caches/async_api_cache\", size_limit=int(2e10))\n",
    "\n",
    "# OpenAI API key setup\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "assert OPENAI_API_KEY is not None, \"Please set the OPENAI_API_KEY environment variable\"\n",
    "\n",
    "# API setup\n",
    "api_config = {\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"request_timeout\": 45,\n",
    "    \"model\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "api = CachedOpenAIAPI(cache, api_config)\n",
    "\n",
    "# Limiter setup\n",
    "limiter = AsyncRoundRobin()\n",
    "N = 4\n",
    "for _ in range(N):\n",
    "    limiter.add_resource(data=OPENAI_API_KEY)\n",
    "\n",
    "prompt = \"What is the capital of France?\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "#response = await api.uncached_request(messages, limiter, n=1)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Setup batching API\n",
    "batch_size = 2\n",
    "bapi = BatchingAPI(batch_size, api, limiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bapi.immediate_request(messages, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Futures : {bapi.futures}\")\n",
    "print(f\"Prompts : {bapi.prompts}\")\n",
    "print(f\"Batches processed : {bapi.num_batches_processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    prompt: str\n",
    "\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    @staticmethod\n",
    "    async def step(state: State, api: BatchingAPI):\n",
    "        # make request\n",
    "        result = await api.buffered_request(state.prompt)\n",
    "\n",
    "        # do something with the result\n",
    "        # ...\n",
    "\n",
    "        return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
