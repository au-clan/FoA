{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import bootstrap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "precision = 3\n",
    "pd.set_option(\"display.precision\", precision)\n",
    "\n",
    "tasks = [\"gameof24\", \"crosswords\"]\n",
    "metrics = {\"gameof24\": \"success_rate\", \"crosswords\": \"r_letter\"}\n",
    "\n",
    "#############################################\n",
    "# Just some util and plot styling functions #\n",
    "#############################################\n",
    "def get_files_in_folder(folder_path):\n",
    "    files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if os.path.isfile(os.path.join(folder_path, file)):\n",
    "            files.append(folder_path + \"/\" +file)\n",
    "    return sorted(files)\n",
    "\n",
    "def get_number(string):\n",
    "    numbers = re.findall(r'\\d+', string)\n",
    "    numbers = list(map(int, numbers))\n",
    "    return numbers[0]\n",
    "\n",
    "def get_params(file_path):\n",
    "    data = {}\n",
    "\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    params = file_name.split('_')\n",
    "\n",
    "    data[\"set\"] = params[0].split(\"-\")[0]\n",
    "    data[\"n_agents\"] = get_number(params[1])\n",
    "    data[\"n_steps\"] = get_number(params[2])\n",
    "    data[\"k\"] = get_number(params[3])\n",
    "    data[\"origin_value\"] = get_number(params[4])\n",
    "    data[\"backtrack\"] = float(\"0.\" + str(get_number(params[5].split(\".\")[1])))\n",
    "    data[\"resampling\"] = params[6].split(\"-\")[0]\n",
    "    data[\"file_path\"] = file_path\n",
    "    data[\"name\"] = f\"{data['n_agents']}agents\\n{data['n_steps']}steps\\n{data['k']}k\\n{data['backtrack']}b\"\n",
    "\n",
    "    return data\n",
    "\n",
    "def compute_stats(puzzle_results, costs):\n",
    "    stats = {}\n",
    "    puzzle_results = np.array(puzzle_results)\n",
    "    performance_stats = bootstrap(puzzle_results.reshape((1,-1)), np.mean)\n",
    "    stats.update({\"performance_mean\":performance_stats.bootstrap_distribution.mean()})\n",
    "    stats.update({\"performance_ci\":performance_stats.confidence_interval})\n",
    "\n",
    "    if len(costs) == 1:\n",
    "        stats.update({\"cost_mean\":costs[0]})\n",
    "        stats.update({\"cost_ci\":(costs[0], costs[0])})\n",
    "    else:\n",
    "        costs = np.array(costs)\n",
    "        cost_stats = bootstrap(costs.reshape((1,-1)), np.mean)\n",
    "        stats.update({\"cost_mean\":cost_stats.bootstrap_distribution.mean()})\n",
    "        stats.update({\"cost_ci\":cost_stats.confidence_interval})\n",
    "\n",
    "    return stats\n",
    "\n",
    "def get_gameof24_puzzle_results_foa(file_path):\n",
    "    with open(file_path, \"r\") as experiment_file:\n",
    "        data = json.load(experiment_file)\n",
    "    \n",
    "    info = data.pop(\"Info\")\n",
    "    cost = info[\"Cost\"][\"Total cost\"][\"total_cost\"]\n",
    "    puzzle_results = []\n",
    "    for _, puzzle in data.items():\n",
    "        puzzle_results.append(({\"r\": 1} in puzzle[\"Verifications\"])*1)\n",
    "    return puzzle_results, cost\n",
    "\n",
    "def get_crosswords_puzzle_results_foa(file_path, metric=\"r_letter\"):\n",
    "    with open(file_path, \"r\") as experiment_file:\n",
    "        data = json.load(experiment_file)\n",
    "    info = data.pop(\"Info\")\n",
    "    cost = info[\"Cost\"][\"Total cost\"][\"total_cost\"]\n",
    "\n",
    "    metrics = {}\n",
    "    for puzzle_id, puzzle_results in data.items():\n",
    "        initial_puzzle = puzzle_results.pop(\"puzzle\", None)       # Not needed just want to pop\n",
    "        verifications = puzzle_results.pop(\"Verifications\", None) # Not needed just want to pop\n",
    "\n",
    "        max_actions = 0\n",
    "        metrics[puzzle_id] = {\"r_letter\": None, \"r_word\": None, \"r_all\": None}\n",
    "        for agent_id, agent_results in puzzle_results.items():\n",
    "            for step_id, step_results in agent_results.items():\n",
    "                step_actions = len(step_results[\"Step\"].split(\" -> \"))\n",
    "                if step_actions > max_actions:\n",
    "                    max_actions = step_actions\n",
    "                    metrics[puzzle_id] = step_results[\"metrics\"]\n",
    "        assert max_actions > 0, f\"No actions found for {puzzle_id}\"\n",
    "\n",
    "    r_letters = [metric[\"r_letter\"] for metric in metrics.values()]\n",
    "    r_words = [metric[\"r_word\"] for metric in metrics.values()]\n",
    "    r_alls = [metric[\"r_all\"] for metric in metrics.values()]\n",
    "    metrics = {\"r_letter\": r_letters, \"r_word\": r_words, \"r_all\": r_alls}\n",
    "\n",
    "    \n",
    "    return metrics[metric], cost\n",
    "\n",
    "\n",
    "get_task_puzzle_results_foa = {\"gameof24\": get_gameof24_puzzle_results_foa, \"crosswords\": get_crosswords_puzzle_results_foa}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "data = {\"gameof24\":{\"cost\":{}, \"performance\":{}, \"both\":{}, \"gpt4\":{}}, \"crosswords\":{\"cost\":{}, \"performance\":{}, \"both\":{}, \"gpt4\":{}}}\n",
    "\n",
    "\"\"\"\n",
    "cost : optimizing for cost\n",
    "performance : optimizing for performance\n",
    "both : optimizing for both\n",
    "mixed : gpt-4 powered evaluation\n",
    "\"\"\"\n",
    "\n",
    "for task, optimizations in data.items():\n",
    "    for optimization, experiments in optimizations.items():\n",
    "        folder = f\"../arxiv/logs/{task}/{optimization}\"\n",
    "        files = get_files_in_folder(folder)\n",
    "        experiments = [get_params(file) for file in files]\n",
    "\n",
    "        configurations = {}\n",
    "        for experiment in experiments:\n",
    "            if experiment[\"name\"] not in configurations:\n",
    "                configurations[experiment[\"name\"]] = []\n",
    "            configurations[experiment[\"name\"]].append(experiment)\n",
    "        \n",
    "        for configuration, experiments in configurations.items():\n",
    "            puzzle_results = []\n",
    "            costs = []\n",
    "            for experiment in experiments:\n",
    "                file_path = experiment[\"file_path\"]\n",
    "                result, cost = get_task_puzzle_results_foa[task](file_path)\n",
    "                costs.append(cost)\n",
    "                puzzle_results.extend(result)\n",
    "            \n",
    "            # Compute stats\n",
    "            stats = compute_stats(puzzle_results, costs)\n",
    "            \n",
    "\n",
    "            data[task][optimization].update({configuration:{\"experiments\": experiments, \"stats\":stats}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gameof24_puzzle_results_tot(file_path, method=\"ToT\"):\n",
    "    with open(file_path, \"r\") as experiment_file:\n",
    "        data = json.load(experiment_file)\n",
    "    \n",
    "    # Get cost\n",
    "    cost = data[-1][\"usage_so_far\"][\"cost\"]\n",
    "\n",
    "    # Get result per puzzle\n",
    "    puzzle_results = []\n",
    "    for puzzle in data:\n",
    "        if method == \"ToT\":\n",
    "            puzzle_results.append(({\"r\": 1} in puzzle[\"infos\"])*1)\n",
    "        else:\n",
    "            puzzle_results.append(np.mean([info[\"r\"] for info in puzzle[\"infos\"]]))\n",
    "    return puzzle_results, cost\n",
    "\n",
    "def get_crosswords_puzzle_results_tot(file_path, metric=\"r_letter\", method=\"ToT\"):\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Get cost\n",
    "    if method != \"ToT\": #ie. naive + cot\n",
    "        cost = data[-1][\"usage_so_far\"][\"cost\"]\n",
    "        r_letters = []\n",
    "        r_words = []\n",
    "        r_games = []\n",
    "        for game in data:\n",
    "            r_letters.append(np.mean([info[\"r_letter\"] for info in game[\"infos\"]]))\n",
    "            r_words.append(np.mean([info[\"r_word\"] for info in game[\"infos\"]]))\n",
    "            r_games.append(np.mean([info[\"r_game\"] for info in game[\"infos\"]]))\n",
    "    \n",
    "    else:\n",
    "        cost = data.pop(-1)[\"cost\"]\n",
    "\n",
    "        # Get results per puzzle\n",
    "        best_steps = []\n",
    "        for game in data:\n",
    "            step_len = [len(step[\"actions\"]) for step in game]\n",
    "            if step_len == []:\n",
    "                # Empty game -> No suggestions at root node\n",
    "                best_steps.append({\"total_step\":0, \"env_step\":0, \"actions\":[], 'info': {'r_letter': 0, 'r_word': 0},})\n",
    "                continue\n",
    "            best_step_index = step_len.index(max(step_len))\n",
    "            best_step = game[best_step_index]\n",
    "            best_steps.append(best_step)\n",
    "\n",
    "        r_letters = [game[\"info\"][\"r_letter\"] for game in best_steps]\n",
    "        r_words = [game[\"info\"][\"r_word\"] for game in best_steps]\n",
    "        r_games = [1 if game[\"info\"][\"r_word\"]==1 else 0 for game in best_steps]\n",
    "        \n",
    "    puzzle_results = {\"r_letter\": r_letters, \"r_word\": r_words, \"r_game\": r_games}\n",
    "\n",
    "    return puzzle_results[metric], cost\n",
    "\n",
    "get_task_puzzle_results_tot = {\"gameof24\": get_gameof24_puzzle_results_tot, \"crosswords\": get_crosswords_puzzle_results_tot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = {\"gameof24\": {\"ToT\": {}}, \"crosswords\": {\"ToT\": {}}} \n",
    "\n",
    "methods = [\"ToT\"] # propose goes for ToT\n",
    "\n",
    "for task in benchmarks.keys():\n",
    "    for method in methods:\n",
    "        folder = f\"../arxiv/benchmarks/{task}/ChatGPT/{method}\"\n",
    "        files = get_files_in_folder(folder)\n",
    "\n",
    "        puzzle_results = []\n",
    "        costs = []\n",
    "\n",
    "        for file in files:\n",
    "            result, cost = get_task_puzzle_results_tot[task](file, method=method)\n",
    "            costs.append(cost)\n",
    "            puzzle_results.extend(result)\n",
    "\n",
    "        # Compute stats\n",
    "        stats = compute_stats(puzzle_results, costs)\n",
    "\n",
    "        benchmarks[task][method] = stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FoA beating ToT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>method</th>\n",
       "      <th>configuration</th>\n",
       "      <th>performance_mean</th>\n",
       "      <th>performance_ci</th>\n",
       "      <th>cost_mean</th>\n",
       "      <th>cost_ci</th>\n",
       "      <th>optimization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>FoA</td>\n",
       "      <td>9agents\\n9steps\\n1k\\n0.5b</td>\n",
       "      <td>0.252</td>\n",
       "      <td>(0.214, 0.29)</td>\n",
       "      <td>1.548</td>\n",
       "      <td>(1.522, 1.58)</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>ToT</td>\n",
       "      <td>default</td>\n",
       "      <td>0.136</td>\n",
       "      <td>(0.108, 0.168)</td>\n",
       "      <td>1.712</td>\n",
       "      <td>(1.636, 1.75)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>FoA</td>\n",
       "      <td>2agents\\n6steps\\n3k\\n0.5b</td>\n",
       "      <td>0.362</td>\n",
       "      <td>(0.325, 0.4)</td>\n",
       "      <td>0.246</td>\n",
       "      <td>(0.238, 0.252)</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>ToT</td>\n",
       "      <td>default</td>\n",
       "      <td>0.333</td>\n",
       "      <td>(0.276, 0.392)</td>\n",
       "      <td>0.481</td>\n",
       "      <td>(0.376, 0.585)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         task method              configuration  performance_mean  \\\n",
       "0    gameof24    FoA  9agents\\n9steps\\n1k\\n0.5b             0.252   \n",
       "1    gameof24    ToT                    default             0.136   \n",
       "2  crosswords    FoA  2agents\\n6steps\\n3k\\n0.5b             0.362   \n",
       "3  crosswords    ToT                    default             0.333   \n",
       "\n",
       "   performance_ci  cost_mean         cost_ci optimization  \n",
       "0   (0.214, 0.29)      1.548   (1.522, 1.58)         both  \n",
       "1  (0.108, 0.168)      1.712   (1.636, 1.75)         None  \n",
       "2    (0.325, 0.4)      0.246  (0.238, 0.252)         both  \n",
       "3  (0.276, 0.392)      0.481  (0.376, 0.585)         None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def group_data_per_optimization(data, benchmarks, optimization, task=None):\n",
    "    results = []\n",
    "\n",
    "    for task_ in data.keys():\n",
    "\n",
    "        # Get FoA results\n",
    "        for configuration, experiment_results in data[task_][optimization].items():\n",
    "            result = {\"task\": task_, \"method\": \"FoA\", \"configuration\": configuration}\n",
    "            result.update(experiment_results[\"stats\"])\n",
    "            result.update({\"optimization\": optimization})\n",
    "            results.append(result)\n",
    "        \n",
    "        # Get ToT results\n",
    "        for method, stats in benchmarks[task_].items():\n",
    "            result = {\"task\": task_, \"method\": method, \"configuration\": \"default\"}\n",
    "            result.update(stats)\n",
    "            result.update({\"optimization\": None})\n",
    "            results.append(result)\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "\n",
    "    for ci in [\"performance_ci\", \"cost_ci\"]:\n",
    "        df[ci] = df[ci].apply(lambda x: (round(x[0], precision), round(x[1], precision)))\n",
    "\n",
    "    # If a task is specified filter the df\n",
    "    if task: \n",
    "        df = df[df.task==task]\n",
    "    return df\n",
    "\n",
    "df_both = group_data_per_optimization(data, benchmarks, \"both\")\n",
    "display(df_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pareto optimals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Optimizing for cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>method</th>\n",
       "      <th>configuration</th>\n",
       "      <th>performance_mean</th>\n",
       "      <th>performance_ci</th>\n",
       "      <th>cost_mean</th>\n",
       "      <th>cost_ci</th>\n",
       "      <th>optimization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>FoA</td>\n",
       "      <td>7agents\\n6steps\\n1k\\n0.5b</td>\n",
       "      <td>0.154</td>\n",
       "      <td>(0.124, 0.188)</td>\n",
       "      <td>1.042</td>\n",
       "      <td>(1.032, 1.05)</td>\n",
       "      <td>cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>ToT</td>\n",
       "      <td>default</td>\n",
       "      <td>0.136</td>\n",
       "      <td>(0.108, 0.168)</td>\n",
       "      <td>1.712</td>\n",
       "      <td>(1.636, 1.75)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>FoA</td>\n",
       "      <td>4agents\\n4steps\\n3k\\n0.5b</td>\n",
       "      <td>0.318</td>\n",
       "      <td>(0.284, 0.352)</td>\n",
       "      <td>0.173</td>\n",
       "      <td>(0.164, 0.176)</td>\n",
       "      <td>cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>ToT</td>\n",
       "      <td>default</td>\n",
       "      <td>0.333</td>\n",
       "      <td>(0.276, 0.392)</td>\n",
       "      <td>0.481</td>\n",
       "      <td>(0.376, 0.585)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         task method              configuration  performance_mean  \\\n",
       "0    gameof24    FoA  7agents\\n6steps\\n1k\\n0.5b             0.154   \n",
       "1    gameof24    ToT                    default             0.136   \n",
       "2  crosswords    FoA  4agents\\n4steps\\n3k\\n0.5b             0.318   \n",
       "3  crosswords    ToT                    default             0.333   \n",
       "\n",
       "   performance_ci  cost_mean         cost_ci optimization  \n",
       "0  (0.124, 0.188)      1.042   (1.032, 1.05)         cost  \n",
       "1  (0.108, 0.168)      1.712   (1.636, 1.75)         None  \n",
       "2  (0.284, 0.352)      0.173  (0.164, 0.176)         cost  \n",
       "3  (0.276, 0.392)      0.481  (0.376, 0.585)         None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cost = group_data_per_optimization(data, benchmarks, \"cost\")\n",
    "display(df_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Optimizing for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>method</th>\n",
       "      <th>configuration</th>\n",
       "      <th>performance_mean</th>\n",
       "      <th>performance_ci</th>\n",
       "      <th>cost_mean</th>\n",
       "      <th>cost_ci</th>\n",
       "      <th>optimization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>FoA</td>\n",
       "      <td>15agents\\n6steps\\n1k\\n0.2b</td>\n",
       "      <td>0.264</td>\n",
       "      <td>(0.226, 0.304)</td>\n",
       "      <td>1.793</td>\n",
       "      <td>(1.771, 1.807)</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>ToT</td>\n",
       "      <td>default</td>\n",
       "      <td>0.136</td>\n",
       "      <td>(0.108, 0.168)</td>\n",
       "      <td>1.712</td>\n",
       "      <td>(1.636, 1.75)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>FoA</td>\n",
       "      <td>4agents\\n6steps\\n3k\\n0.5b</td>\n",
       "      <td>0.402</td>\n",
       "      <td>(0.36, 0.442)</td>\n",
       "      <td>0.481</td>\n",
       "      <td>(0.47, 0.499)</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>ToT</td>\n",
       "      <td>default</td>\n",
       "      <td>0.333</td>\n",
       "      <td>(0.276, 0.392)</td>\n",
       "      <td>0.481</td>\n",
       "      <td>(0.376, 0.585)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         task method               configuration  performance_mean  \\\n",
       "0    gameof24    FoA  15agents\\n6steps\\n1k\\n0.2b             0.264   \n",
       "1    gameof24    ToT                     default             0.136   \n",
       "2  crosswords    FoA   4agents\\n6steps\\n3k\\n0.5b             0.402   \n",
       "3  crosswords    ToT                     default             0.333   \n",
       "\n",
       "   performance_ci  cost_mean         cost_ci optimization  \n",
       "0  (0.226, 0.304)      1.793  (1.771, 1.807)  performance  \n",
       "1  (0.108, 0.168)      1.712   (1.636, 1.75)         None  \n",
       "2   (0.36, 0.442)      0.481   (0.47, 0.499)  performance  \n",
       "3  (0.276, 0.392)      0.481  (0.376, 0.585)         None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_performance = group_data_per_optimization(data, benchmarks, \"performance\")\n",
    "display(df_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>method</th>\n",
       "      <th>configuration</th>\n",
       "      <th>performance_mean</th>\n",
       "      <th>performance_ci</th>\n",
       "      <th>cost_mean</th>\n",
       "      <th>cost_ci</th>\n",
       "      <th>optimization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>FoA</td>\n",
       "      <td>9agents\\n9steps\\n1k\\n0.5b</td>\n",
       "      <td>0.252</td>\n",
       "      <td>(0.214, 0.29)</td>\n",
       "      <td>1.548</td>\n",
       "      <td>(1.522, 1.58)</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>FoA</td>\n",
       "      <td>7agents\\n6steps\\n1k\\n0.5b</td>\n",
       "      <td>0.154</td>\n",
       "      <td>(0.124, 0.188)</td>\n",
       "      <td>1.042</td>\n",
       "      <td>(1.032, 1.05)</td>\n",
       "      <td>cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>FoA</td>\n",
       "      <td>15agents\\n6steps\\n1k\\n0.2b</td>\n",
       "      <td>0.264</td>\n",
       "      <td>(0.226, 0.304)</td>\n",
       "      <td>1.793</td>\n",
       "      <td>(1.771, 1.807)</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>ToT</td>\n",
       "      <td>default</td>\n",
       "      <td>0.136</td>\n",
       "      <td>(0.108, 0.168)</td>\n",
       "      <td>1.712</td>\n",
       "      <td>(1.636, 1.75)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>FoA</td>\n",
       "      <td>2agents\\n6steps\\n3k\\n0.5b</td>\n",
       "      <td>0.362</td>\n",
       "      <td>(0.325, 0.4)</td>\n",
       "      <td>0.246</td>\n",
       "      <td>(0.238, 0.252)</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>FoA</td>\n",
       "      <td>4agents\\n4steps\\n3k\\n0.5b</td>\n",
       "      <td>0.318</td>\n",
       "      <td>(0.284, 0.352)</td>\n",
       "      <td>0.173</td>\n",
       "      <td>(0.164, 0.176)</td>\n",
       "      <td>cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>FoA</td>\n",
       "      <td>4agents\\n6steps\\n3k\\n0.5b</td>\n",
       "      <td>0.402</td>\n",
       "      <td>(0.36, 0.442)</td>\n",
       "      <td>0.481</td>\n",
       "      <td>(0.47, 0.499)</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>ToT</td>\n",
       "      <td>default</td>\n",
       "      <td>0.333</td>\n",
       "      <td>(0.276, 0.392)</td>\n",
       "      <td>0.481</td>\n",
       "      <td>(0.376, 0.585)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         task method               configuration  performance_mean  \\\n",
       "0    gameof24    FoA   9agents\\n9steps\\n1k\\n0.5b             0.252   \n",
       "1    gameof24    FoA   7agents\\n6steps\\n1k\\n0.5b             0.154   \n",
       "2    gameof24    FoA  15agents\\n6steps\\n1k\\n0.2b             0.264   \n",
       "3    gameof24    ToT                     default             0.136   \n",
       "4  crosswords    FoA   2agents\\n6steps\\n3k\\n0.5b             0.362   \n",
       "5  crosswords    FoA   4agents\\n4steps\\n3k\\n0.5b             0.318   \n",
       "6  crosswords    FoA   4agents\\n6steps\\n3k\\n0.5b             0.402   \n",
       "7  crosswords    ToT                     default             0.333   \n",
       "\n",
       "   performance_ci  cost_mean         cost_ci optimization  \n",
       "0   (0.214, 0.29)      1.548   (1.522, 1.58)         both  \n",
       "1  (0.124, 0.188)      1.042   (1.032, 1.05)         cost  \n",
       "2  (0.226, 0.304)      1.793  (1.771, 1.807)  performance  \n",
       "3  (0.108, 0.168)      1.712   (1.636, 1.75)         None  \n",
       "4    (0.325, 0.4)      0.246  (0.238, 0.252)         both  \n",
       "5  (0.284, 0.352)      0.173  (0.164, 0.176)         cost  \n",
       "6   (0.36, 0.442)      0.481   (0.47, 0.499)  performance  \n",
       "7  (0.276, 0.392)      0.481  (0.376, 0.585)         None  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_both, df_cost, df_performance])\n",
    "df.sort_values(by=[\"task\", \"method\", \"optimization\"], ascending=[False, True, True],inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT4 Benchmarks\n",
    "benchmarks = {\"gameof24\": {\"ToT\": {}}, \"crosswords\": {\"ToT\": {}}} \n",
    "\n",
    "methods = [\"ToT\"] # propose goes for ToT\n",
    "\n",
    "for task in benchmarks.keys():\n",
    "    for method in methods:\n",
    "        folder = f\"../arxiv/benchmarks/{task}/GPT4/{method}\"\n",
    "        files = get_files_in_folder(folder)\n",
    "\n",
    "        puzzle_results = []\n",
    "        costs = []\n",
    "\n",
    "        for file in files:\n",
    "            result, cost = get_task_puzzle_results_tot[task](file, method=method)\n",
    "            costs.append(cost)\n",
    "            puzzle_results.extend(result)\n",
    "\n",
    "        # Compute stats\n",
    "        stats = compute_stats(puzzle_results, costs)\n",
    "\n",
    "        benchmarks[task][method] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>method</th>\n",
       "      <th>configuration</th>\n",
       "      <th>performance_mean</th>\n",
       "      <th>performance_ci</th>\n",
       "      <th>cost_mean</th>\n",
       "      <th>cost_ci</th>\n",
       "      <th>optimization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>FoA</td>\n",
       "      <td>9agents\\n9steps\\n1k\\n0.5b</td>\n",
       "      <td>0.760</td>\n",
       "      <td>(0.67, 0.84)</td>\n",
       "      <td>62.930</td>\n",
       "      <td>(62.93, 62.93)</td>\n",
       "      <td>gpt4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gameof24</td>\n",
       "      <td>ToT</td>\n",
       "      <td>default</td>\n",
       "      <td>0.750</td>\n",
       "      <td>(0.66, 0.83)</td>\n",
       "      <td>75.024</td>\n",
       "      <td>(75.024, 75.024)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>FoA</td>\n",
       "      <td>2agents\\n6steps\\n3k\\n0.5b</td>\n",
       "      <td>0.460</td>\n",
       "      <td>(0.342, 0.566)</td>\n",
       "      <td>12.938</td>\n",
       "      <td>(12.938, 12.938)</td>\n",
       "      <td>gpt4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crosswords</td>\n",
       "      <td>ToT</td>\n",
       "      <td>default</td>\n",
       "      <td>0.394</td>\n",
       "      <td>(0.256, 0.544)</td>\n",
       "      <td>48.989</td>\n",
       "      <td>(48.989, 48.989)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         task method              configuration  performance_mean  \\\n",
       "0    gameof24    FoA  9agents\\n9steps\\n1k\\n0.5b             0.760   \n",
       "1    gameof24    ToT                    default             0.750   \n",
       "2  crosswords    FoA  2agents\\n6steps\\n3k\\n0.5b             0.460   \n",
       "3  crosswords    ToT                    default             0.394   \n",
       "\n",
       "   performance_ci  cost_mean           cost_ci optimization  \n",
       "0    (0.67, 0.84)     62.930    (62.93, 62.93)         gpt4  \n",
       "1    (0.66, 0.83)     75.024  (75.024, 75.024)         None  \n",
       "2  (0.342, 0.566)     12.938  (12.938, 12.938)         gpt4  \n",
       "3  (0.256, 0.544)     48.989  (48.989, 48.989)         None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = group_data_per_optimization(data, benchmarks, \"gpt4\")\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
