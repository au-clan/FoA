{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class GameOf24State:\n",
    "    # game of 24 puzzle, for example 1 1 4 6\n",
    "    puzzle: str\n",
    "\n",
    "    # initialized to the same value as puzzle, but is updated as the game progresses\n",
    "    current_state: str\n",
    "\n",
    "    steps: List[str]\n",
    "\n",
    "    #Randomness used for resampling (random seed)\n",
    "    randomness: int\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.puzzle, self.current_state, \" -> \".join(self.steps)))\n",
    "    \n",
    "    def items(self):\n",
    "        return self.puzzle, self.current_state, self.steps, self.randomness\n",
    "    \n",
    "    def duplicate(self, randomness=None):\n",
    "        return GameOf24State(\n",
    "            puzzle=self.puzzle,\n",
    "            current_state=self.current_state,\n",
    "            steps=self.steps,\n",
    "            randomness=randomness if randomness is not None else self.randomness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method GameOf24State.items of GameOf24State(puzzle='1 1 4 6', current_state='1 1 4 6', steps=[], randomness=853)>\n",
      "Stepping...\n",
      "<bound method GameOf24State.items of GameOf24State(puzzle='1 1 4 6', current_state='1 4 6', steps=['1 * 1 = 1'], randomness=932)>\n",
      "Stepping...\n",
      "<bound method GameOf24State.items of GameOf24State(puzzle='1 1 4 6', current_state='1 24', steps=['1 * 1 = 1', '4 * 6 = 24'], randomness=842)>\n"
     ]
    }
   ],
   "source": [
    "#Testing the game of 24\n",
    "\n",
    "import random\n",
    "\n",
    "states = []\n",
    "puzzle = \"1 1 4 6\"\n",
    "game_env = GameOf24State(puzzle=puzzle, current_state=puzzle, steps=[], randomness=random.randint(0, 1000))\n",
    "\n",
    "# for step in range(2):\n",
    "#     print(f\"Step {step} : Stepping\")\n",
    "\n",
    "print(game_env.items)\n",
    "\n",
    "print(\"Stepping...\")\n",
    "game_env = GameOf24State(puzzle=\"1 1 4 6\", current_state=\"1 4 6\", steps=game_env.steps + [\"1 * 1 = 1\"], randomness=random.randint(0, 1000))\n",
    "\n",
    "print(game_env.items)\n",
    "\n",
    "print(\"Stepping...\")\n",
    "\n",
    "\n",
    "game_env = GameOf24State(puzzle=\"1 1 4 6\", current_state=\"1 24\", steps=game_env.steps + [\"4 * 6 = 24\"], randomness=random.randint(0, 1000))\n",
    "\n",
    "print(game_env.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reflexion agent :O\n",
    "\n",
    "import asyncio\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from sympy import simplify\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "from src.prompts.totor import gameof24 as totor_prompts\n",
    "from src.prompts.adapt import gameof24 as llama_prompts\n",
    "from src.states.gameof24 import GameOf24State\n",
    "from utils import parse_suggestions, create_box\n",
    "\n",
    "\n",
    "class GameOf24Agent:\n",
    "\n",
    "    @staticmethod\n",
    "    async def step(state: GameOf24State, api, namespace)-> GameOf24State:\n",
    "        \"\"\"\n",
    "        Given a state, returns the next state one.\n",
    "        \"\"\"\n",
    "\n",
    "        # set up the prompt, based on the current state\n",
    "\n",
    "        # ToT uses bfs_prompt to generate next steps but then uses\n",
    "        # the cot_prompt to get the final expression. \n",
    "        # For example, input : 1 1 4 6\n",
    "        # Step 0 : '1 - 1 = 0 (left: 0 4 6)'          BFS prompt\n",
    "        # Step 1 : '0 + 4 = 4 (left: 4 6)'            BFS prompt\n",
    "        # Step 2 : '4 * 6 = 24 (left: 24)'            BFS prompt\n",
    "        # Step 3 : Answer : ((1 - 1) + 4) * 6 = 24    CoT prompt\n",
    "\n",
    "\n",
    "        # set up the prompt, based on the current state\n",
    "        current_state = state.current_state\n",
    "        print(current_state)\n",
    "        if current_state.strip() == \"24\":\n",
    "            # CoT prompt\n",
    "            steps = \"\\n\".join(state.steps) + \"\\n\"\n",
    "            \n",
    "            # Set up CoT prompt\n",
    "            if any(author in api.model for author in [\"meta\", \"google\", \"mistral\", \"gpt-4o\"]):\n",
    "                prompt = llama_prompts.cot_prompt.format(input=state.puzzle) + \"Steps:\\n\" + steps + \"Answer: \"\n",
    "            else:\n",
    "                prompt = totor_prompts.cot_prompt.format(input=state.puzzle) + \"Steps:\\n\" + steps\n",
    "\n",
    "            # Get the final expression\n",
    "            suggestions = await api.buffered_request(prompt, key=hash(state), namespace=namespace)\n",
    "\n",
    "            # State does not change, only the steps\n",
    "            selected_suggestion = suggestions\n",
    "            selected_state = state.current_state\n",
    "\n",
    "            prompt = \"We are playing game of 24 make sure not to use duplicates\" + \"This is the current state\" + state.current_state\n",
    "            # Get the next state\n",
    "            suggestions = await api.buffered_request(prompt, key=hash(state), namespace=namespace)\n",
    "        else:\n",
    "            reflexion_prompt = \"You are reflecting\"\n",
    "            # Get the next state\n",
    "            reflexion_suggestions = await api.buffered_request(prompt, key=hash(state), namespace=namespace)\n",
    "                \n",
    "            # Set up BFS prompt\n",
    "            if any(author in api.model for author in [\"meta\", \"google\", \"mistral\", \"gpt-4o\"]):\n",
    "                prompt = llama_prompts.bfs_prompt.format(input=current_state)\n",
    "            else:\n",
    "                prompt = totor_prompts.bfs_prompt.format(input=current_state)\n",
    "\n",
    "            # Get the next state\n",
    "            suggestions = await api.buffered_request(prompt, key=hash(state), namespace=namespace)\n",
    "\n",
    "            # parse suggestions, based on the current state\n",
    "            parsed_suggestions = parse_suggestions(suggestions)\n",
    "            if parsed_suggestions == []:\n",
    "                print(f\"No suggestions were paresed from state: {state}\")\n",
    "                print(f\"\\nPrompt: {prompt}\\nSuggestions: {suggestions}\\nParsed suggestions: {' | '.join(parsed_suggestions)}\\n\")\n",
    "                assert False, \"No suggestions found.\"\n",
    "            \n",
    "            suggestions = parsed_suggestions\n",
    "            \n",
    "            random.seed(state.randomness)\n",
    "            selected_suggestion = random.choice(suggestions)\n",
    "            selected_state = GameOf24Agent.parse_next_state(selected_suggestion)\n",
    "\n",
    "        # set up new state object\n",
    "        next_state = GameOf24State(\n",
    "            puzzle=state.puzzle,\n",
    "            current_state=selected_state,\n",
    "            steps=state.steps + [selected_suggestion],\n",
    "            randomness=random.randint(0, 1000)\n",
    "        )\n",
    "        return next_state\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_next_state(suggestion: str) -> str:\n",
    "        return suggestion.split('left: ')[-1].split(')')[0]\n",
    "\n",
    "    @staticmethod\n",
    "    async def reflection(state: GameOf24State, api, namespace):\n",
    "        prompt = \"We are playing game of 24 make sure not to use duplicates\" + \"This is the current state\" + state.current_state\n",
    "        # Get the next state\n",
    "        suggestions = await api.buffered_request(prompt, key=hash(state), namespace=namespace)\n",
    "\n",
    "        return suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : Stepping\n",
      "1 1 4 6\n",
      "[GameOf24State(puzzle='1 1 4 6', current_state='1 2 4', steps=['1. 1 + 1 = 2 (left: 1 2 4)'], randomness=952)]\n",
      "Step 1 : Stepping\n",
      "1 2 4\n",
      "[GameOf24State(puzzle='1 1 4 6', current_state=\"To find the next possible steps for the input 1 2 4, we'll apply the same operations as before: addition, subtraction, multiplication, and division.\", steps=['1. 1 + 1 = 2 (left: 1 2 4)', \"To find the next possible steps for the input 1 2 4, we'll apply the same operations as before: addition, subtraction, multiplication, and division.\"], randomness=690)]\n",
      "Step 2 : Stepping\n",
      "To find the next possible steps for the input 1 2 4, we'll apply the same operations as before: addition, subtraction, multiplication, and division.\n",
      "[GameOf24State(puzzle='1 1 4 6', current_state='Possible next steps:', steps=['1. 1 + 1 = 2 (left: 1 2 4)', \"To find the next possible steps for the input 1 2 4, we'll apply the same operations as before: addition, subtraction, multiplication, and division.\", 'Possible next steps:'], randomness=738)]\n",
      "Step 3 : Stepping\n",
      "Possible next steps:\n",
      "[GameOf24State(puzzle='1 1 4 6', current_state='', steps=['1. 1 + 1 = 2 (left: 1 2 4)', \"To find the next possible steps for the input 1 2 4, we'll apply the same operations as before: addition, subtraction, multiplication, and division.\", 'Possible next steps:', ''], randomness=94)]\n"
     ]
    }
   ],
   "source": [
    "from async_engine.batched_api import BatchingAPI\n",
    "from async_engine.api import API\n",
    "\n",
    "\n",
    "step_api_config = eval_api_config = {\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"request_timeout\": 120,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "model = \"llama-3.2-11b-vision-preview\"\n",
    "# provider = \"TogetherAI\" if \"meta\" in model else \"OpenAI\"\n",
    "provider = \"Groq\"\n",
    "# provider = \"TogetherAI\"\n",
    "models = {\n",
    "    \"step\": {\"model_name\":model, \"provider\":provider},\n",
    "    \"eval\": {\"model_name\":model, \"provider\":provider},\n",
    "}\n",
    "\n",
    "api = API(eval_api_config, models=models.values(), resources=2, verbose=False)\n",
    "\n",
    "\n",
    "states = []\n",
    "puzzle = \"1 1 4 6\"\n",
    "num_steps = 4\n",
    "\n",
    "#Create initial state/environment\n",
    "game_env = GameOf24State(puzzle=puzzle, current_state=puzzle, steps=[], randomness=random.randint(0, 1000))\n",
    "step_batcher = BatchingAPI(api, batch_size=1, timeout=2, model=models[\"step\"][\"model_name\"], tab=\"step\")\n",
    "\n",
    "states.append(game_env)\n",
    "\n",
    "agent_coroutines = []\n",
    "for step in range(num_steps):\n",
    "    \n",
    "    print(f\"Step {step} : Stepping\")\n",
    "    \n",
    "    #Stepping - This does not work for us, without using asyncio.create_task(), why?\n",
    "    agent_tasks = [\n",
    "        asyncio.create_task(\n",
    "        GameOf24Agent.step(state, step_batcher, namespace=(0, f\"Agent: {agent_id}\", f\"Step : {step}\"))\n",
    "        )\n",
    "        for agent_id, state in enumerate(states)\n",
    "    ]\n",
    "    states = await asyncio.gather(*agent_tasks)\n",
    "\n",
    "    print(states)\n",
    "\n",
    "    agent_tasks = [\n",
    "        asyncio.create_task(\n",
    "            GameOf24Agent.reflection(state, step_batcher, namespace=(0, f\"Agent: {agent_id}\", f\"Step : {step}\"))\n",
    "        )\n",
    "        for agent_id, state in enumerate(states)\n",
    "    ]\n",
    "    reflections = await asyncio.gather(*agent_tasks)\n",
    "    # print(reflections)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
