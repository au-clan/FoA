{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "import random\n",
    "\n",
    "import asyncio\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from sympy import simplify\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "from async_engine.batched_api import BatchingAPI\n",
    "from async_engine.api import API\n",
    "\n",
    "from src.prompts.adapt import gameof24 as llama_prompts\n",
    "from utils import parse_suggestions, create_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State class\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class GameOf24State:\n",
    "    # game of 24 puzzle, for example 1 1 4 6\n",
    "    puzzle: str\n",
    "\n",
    "    # initialized to the same value as puzzle, but is updated as the game progresses\n",
    "    current_state: str\n",
    "\n",
    "    steps: List[str]\n",
    "\n",
    "    #Randomness used for resampling (random seed)\n",
    "    randomness: int\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.puzzle, self.current_state, \" -> \".join(self.steps)))\n",
    "    \n",
    "    def items(self):\n",
    "        return self.puzzle, self.current_state, self.steps, self.randomness\n",
    "    \n",
    "    def duplicate(self, randomness=None):\n",
    "        return GameOf24State(\n",
    "            puzzle=self.puzzle,\n",
    "            current_state=self.current_state,\n",
    "            steps=self.steps,\n",
    "            randomness=randomness if randomness is not None else self.randomness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the game of 24\n",
    "\n",
    "states = []\n",
    "puzzle = \"1 1 4 6\"\n",
    "example = GameOf24State(puzzle=puzzle, current_state=puzzle, steps=[], randomness=random.randint(0, 1000))\n",
    "\n",
    "# for step in range(2):\n",
    "#     print(f\"Step {step} : Stepping\")\n",
    "\n",
    "print(\"Initial State\")\n",
    "print(example.items(), \"\\n\")\n",
    "\n",
    "print(\"Step: 0\")\n",
    "example = GameOf24State(puzzle=\"1 1 4 6\", current_state=\"1 4 6\", steps=example.steps + [\"1 * 1 = 1\"], randomness=random.randint(0, 1000))\n",
    "print(example.items(), \"\\n\")\n",
    "\n",
    "\n",
    "print(\"Step: 1\")\n",
    "example = GameOf24State(puzzle=\"1 1 4 6\", current_state=\"1 24\", steps=example.steps + [\"4 * 6 = 24\"], randomness=random.randint(0, 1000))\n",
    "print(example.items(), \"\\n\")\n",
    "\n",
    "print(\"Step: 2\")\n",
    "example = GameOf24State(puzzle=\"1 1 4 6\", current_state=\"24\", steps=example.steps + [\"1 * 24 = 25\"], randomness=random.randint(0, 1000))\n",
    "print(example.items(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reflexion agent :O\n",
    "\n",
    "class GameOf24Agent:\n",
    "\n",
    "    @staticmethod\n",
    "    async def step(state: GameOf24State, api, namespace, reflection: list)-> GameOf24State:\n",
    "        \"\"\"\n",
    "        Given a state, returns the next state one.\n",
    "        \"\"\"\n",
    "\n",
    "        # set up the prompt, based on the current state\n",
    "\n",
    "        # ToT uses bfs_prompt to generate next steps but then uses\n",
    "        # the cot_prompt to get the final expression. \n",
    "        # For example, input : 1 1 4 6\n",
    "        # Step 0 : '1 - 1 = 0 (left: 0 4 6)'          BFS prompt\n",
    "        # Step 1 : '0 + 4 = 4 (left: 4 6)'            BFS prompt\n",
    "        # Step 2 : '4 * 6 = 24 (left: 24)'            BFS prompt\n",
    "        # Step 3 : Answer : ((1 - 1) + 4) * 6 = 24    CoT prompt\n",
    "\n",
    "\n",
    "        # set up the prompt, based on the current state\n",
    "\n",
    "        current_state = state.current_state\n",
    "        \n",
    "        if current_state.strip() == \"24\":\n",
    "            # CoT prompt\n",
    "            steps = \"\\n\".join(state.steps) + \"\\n\"\n",
    "            \n",
    "            if len(reflection) == 0:\n",
    "                prompt = llama_prompts.cot_prompt.format(input=state.puzzle) + \"Steps:\\n\" + steps + \"Answer: \"\n",
    "            else:\n",
    "                prompt = llama_prompts.bfs_reflexion_prompt.format(input=current_state, puzzle = \"1 1 4 6\", reflection=reflection[0], steps=reflection[1]) \n",
    "            \n",
    "\n",
    "            # Set up CoT prompt\n",
    "            # if any(author in api.model for author in [\"meta\", \"google\", \"mistral\", \"gpt-4o\"]):\n",
    "            #     prompt = llama_prompts.cot_prompt.format(input=state.puzzle) + \"Steps:\\n\" + steps + \"Answer: \"\n",
    "            # else:\n",
    "            #     prompt = totor_prompts.cot_prompt.format(input=state.puzzle) + \"Steps:\\n\" + steps\n",
    "\n",
    "            # Get the final expression\n",
    "            suggestions = await api.buffered_request(prompt, key=hash(state), namespace=namespace)\n",
    "\n",
    "            # State does not change, only the steps\n",
    "            selected_suggestion = suggestions\n",
    "            selected_state = state.current_state\n",
    "            \n",
    "\n",
    "\n",
    "        else:\n",
    "            if len(reflection) == 0:\n",
    "                prompt = llama_prompts.bfs_prompt.format(input=current_state) \n",
    "            else:\n",
    "                prompt = llama_prompts.bfs_reflexion_prompt.format(input=current_state, puzzle = \"1 1 4 6\", reflection=reflection[0], steps=reflection[1]) \n",
    "                \n",
    "            # Set up BFS prompt\n",
    "            # if any(author in api.model for author in [\"meta\", \"google\", \"mistral\", \"gpt-4o\"]):\n",
    "            #     prompt = llama_prompts.bfs_prompt.format(input=current_state) + \"Keep in mind the following critique from the last step: \\n\" + reflexion_suggestions\n",
    "            # else:\n",
    "            #     prompt = totor_prompts.bfs_prompt.format(input=current_state) + \"Keep in mind the following critique from the last step: \\n\" + reflexion_suggestions\n",
    "\n",
    "            # Get the next state\n",
    "            # suggestions = await api.buffered_request(prompt, key=hash(state), namespace=namespace)\n",
    "\n",
    "            suggestions = await api.buffered_request(prompt, key=hash(state), namespace=namespace)\n",
    "            #print(\"suggestions: \", suggestions)\n",
    "\n",
    "            # parse suggestions, based on the current state\n",
    "            parsed_suggestions = parse_suggestions(suggestions)\n",
    "            if parsed_suggestions == []:\n",
    "                print(f\"No suggestions were paresed from state: {state}\")\n",
    "                print(f\"\\nPrompt: {prompt}\\nSuggestions: {suggestions}\\nParsed suggestions: {' | '.join(parsed_suggestions)}\\n\")\n",
    "                assert False, \"No suggestions found.\"\n",
    "            \n",
    "            suggestions = parsed_suggestions\n",
    "            \n",
    "            random.seed(state.randomness)\n",
    "            selected_suggestion = random.choice(suggestions)\n",
    "            selected_state = GameOf24Agent.parse_next_state(selected_suggestion)\n",
    "\n",
    "        # set up new state object\n",
    "        next_state = GameOf24State(\n",
    "            puzzle=state.puzzle,\n",
    "            current_state=selected_state,\n",
    "            steps=state.steps + [selected_suggestion],\n",
    "            randomness=random.randint(0, 1000)\n",
    "        )\n",
    "        return next_state\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_next_state(suggestion: str) -> str:\n",
    "        return suggestion.split('left: ')[-1].split(')')[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def verify(state: GameOf24State)-> dict:\n",
    "            \"\"\"\n",
    "            Verifies the output of a given task\n",
    "                1. Checks if the numbers used are the same as the ones provided.\n",
    "                2. Checks if the operations performed result to 24.\n",
    "\n",
    "            States \n",
    "                {\"r\": 0} : Not finished.\n",
    "                {\"r\": 1} : Finished and correct.\n",
    "                {\"r\": -1} : Finished and incorrect.\n",
    "            \"\"\"\n",
    "            current_states = state.current_state.split(\" \")\n",
    "            if len(current_states) !=1 or len(state.steps)<=3:\n",
    "                # More than one number left\n",
    "                return {'r':0}\n",
    "            elif current_states[0] != \"24\":\n",
    "                # One number left and it is not 24\n",
    "                return {'r':-1}\n",
    "            else:\n",
    "                # One number left and it is 24\n",
    "                expression = state.steps[-1].lower().replace('answer: ', '').split('=')[0]\n",
    "                numbers = re.findall(r'\\d+', expression)\n",
    "                problem_numbers = re.findall(r'\\d+', state.puzzle)\n",
    "                if sorted(numbers) != sorted(problem_numbers):\n",
    "                    # Numbers used are not the same as the ones provided\n",
    "                    return {'r': -1}\n",
    "                try:\n",
    "                    if simplify(expression) == 24:\n",
    "                        return {'r': 1}\n",
    "                    else:\n",
    "                        # Operations performed do not result to 24\n",
    "                        return {'r': -1}\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    return {'r': -1}\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_reflection(puzzle: str, steps, state: GameOf24State, api, namespace) -> str:\n",
    "        prompt = llama_prompts.reflexion_prompt.format(puzzle=puzzle, steps=steps)\n",
    "        reflection = api.buffered_request(prompt, key=hash(state), namespace=namespace)\n",
    "        return reflection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve 1 1 4 6 puzzle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "step_api_config = eval_api_config = {\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"request_timeout\": 120,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "# eligible providers [\"TogehterAI\", \"OpenAI\", \"Groq\"]\n",
    "model = \"llama-3.3-70b-versatile\"\n",
    "provider = \"Groq\"\n",
    "models = {\n",
    "    \"step\": {\"model_name\":model, \"provider\":provider},\n",
    "    \"eval\": {\"model_name\":model, \"provider\":provider},\n",
    "}\n",
    "\n",
    "api = API(eval_api_config, models=models.values(), resources=2, verbose=False)\n",
    "\n",
    "states = []\n",
    "puzzle = \"1 1 4 6\"\n",
    "num_steps = 4\n",
    "\n",
    "#Create initial state/environment\n",
    "game_env = GameOf24State(puzzle=puzzle, current_state=puzzle, steps=[], randomness=random.randint(0, 1000))\n",
    "step_batcher = BatchingAPI(api, batch_size=1, timeout=2, model=models[\"step\"][\"model_name\"], tab=\"step\")\n",
    "\n",
    "states.append(game_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to solve the puzzle (without reflexion)\n",
    "\n",
    "states = [game_env]\n",
    "finished_states = []\n",
    "\n",
    "#Stepping\n",
    "for step in range(num_steps):\n",
    "    \n",
    "    print(f\"Step {step} : Stepping\")\n",
    "    agent_tasks = [\n",
    "        asyncio.create_task(\n",
    "        GameOf24Agent.step(state, step_batcher, namespace=(0, f\"Agent: {agent_id}\", f\"Step : {step}\"), reflection=\"\")\n",
    "        )\n",
    "        for agent_id, state in enumerate(states)\n",
    "    ]\n",
    "    states = await asyncio.gather(*agent_tasks)\n",
    "    print(f\"Current step: {states[-1].steps[-1]} \\n\")\n",
    "\n",
    "    # Evaluate whether a puzzle has been solved\n",
    "    i = 0\n",
    "    while i < len(states):\n",
    "        if GameOf24Agent.verify(states[i]) == {\"r\": 1}:\n",
    "            print(f\"Puzzle finished: {states[i].puzzle}\")\n",
    "            finished_states.append(states.pop(i))\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # If all puzzles have been solved, break\n",
    "    if len(states) == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reflexions if the puzzle is not solved\n",
    "\n",
    "agent_reflections = [\n",
    "    asyncio.create_task(\n",
    "    GameOf24Agent.generate_reflection(puzzle=puzzle, steps=state.steps, state=state, api=step_batcher, namespace=(0, f\"Agent: {agent_id}\", f\"Step : {step}\"))\n",
    "    )\n",
    "    for agent_id, state in enumerate(states)\n",
    "]\n",
    "reflection = await asyncio.gather(*agent_reflections)\n",
    "reflection.append(states[0].steps)\n",
    "\n",
    "print(f\"Reflection: {reflection[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reattempting to solve the puzzle (with reflexion)\n",
    "\n",
    "#Resetting\n",
    "states = [game_env]\n",
    "finished_states = []\n",
    "\n",
    "#Stepping\n",
    "for step in range(num_steps):\n",
    "    \n",
    "    print(f\"Step {step} : Stepping\")\n",
    "    agent_tasks = [\n",
    "        asyncio.create_task(\n",
    "        GameOf24Agent.step(state, step_batcher, namespace=(0, f\"Agent: {agent_id}\", f\"Step : {step}\"), reflection=reflection)\n",
    "        )\n",
    "        for agent_id, state in enumerate(states)\n",
    "    ]\n",
    "    states = await asyncio.gather(*agent_tasks)\n",
    "    print(f\"Current step: {states[-1].steps[-1]} \\n\")\n",
    "\n",
    "    # Evaluate whether a puzzle has been solved\n",
    "    i = 0\n",
    "    while i < len(states):\n",
    "        if GameOf24Agent.verify(states[i]) == {\"r\": 1}:\n",
    "            print(f\"Puzzle finished: {states[i].puzzle}\")\n",
    "            finished_states.append(states.pop(i))\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # If all puzzles have been solved, break\n",
    "    if len(states) == 0:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
