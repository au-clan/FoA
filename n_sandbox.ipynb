{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook\n",
    "This is a testing notebook, serving no other purpose other than testing things out while developping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "from src.models import OpenAIBot\n",
    "from src.prompts.game24 import foa_step_prompt, value_prompt, value_last_step_prompt, bfs_prompt\n",
    "from src.tasks.base import DATA_PATH\n",
    "from src.tasks.game24 import Game24\n",
    "from src.methods.agents import Agents\n",
    "from src.methods.resampler import Resampler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "bot = OpenAIBot(model=\"gpt-3.5-turbo-1106\")\n",
    "#bot = OpenAIBot(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt testing\n",
    "from src.prompts.game24 import foa_step_prompt, value_prompt, value_last_step_prompt, bfs_prompt, cot_prompt\n",
    "x = 20\n",
    "input = \"1 24\"\n",
    "\n",
    "prompt = foa_step_prompt.format(input=input) \n",
    "\n",
    "for i in range(x):\n",
    "    response = bot.request(prompt)\n",
    "\n",
    "print(f\"Prompt \\n{prompt}\")\n",
    "print(\"----\\n----\\n\")\n",
    "print(f\"Response \\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game24 task step function\n",
    "\n",
    "task = Game24(bot)\n",
    "idx = randint(0, len(task))\n",
    "task.get_input(idx)\n",
    "\n",
    "\n",
    "value_numbers = []\n",
    "for i in range(task.max_steps):\n",
    "    task.step()\n",
    "    value_number = task.evaluate()\n",
    "    value_numbers.append(value_number)\n",
    "summary = []\n",
    "\n",
    "for i in range(len(task.steps)):\n",
    "    temp = task.steps[i] + f\" [Value : {value_numbers[i]}]\"\n",
    "    summary.append(temp)\n",
    "\n",
    "print(f\"Input: {task.input}\")\n",
    "print(\"\\n\".join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampler\n",
    "\n",
    "values = np.array([20, 10, 5, 1, 0.0001])\n",
    "resampler = Resampler()\n",
    "\n",
    "# Normalized resampling\n",
    "draw = resampler.resample(values, resample_method=\"normalization\")\n",
    "print(f\"Normalized : {draw}\")\n",
    "\n",
    "\n",
    "# Greedy\n",
    "draw = resampler.resample(values, resample_method=\"greedy\")\n",
    "print(f\"Greedy : {draw}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple agents\n",
    "\n",
    "idx_input = 8\n",
    "n_evaluations = 2\n",
    "n_agents = 2\n",
    "\n",
    "# Create agents\n",
    "agents = Agents(task=Game24, idx_input=idx_input, n_agents=n_agents, init=False, model=bot, n_evaluations=2)\n",
    "\n",
    "# Run agents\n",
    "for i in range(agents.max_steps-1):\n",
    "    agents.step()\n",
    "    agents.evaluate()\n",
    "    agents.resample()\n",
    "\n",
    "# Final step : Finish answers format + Choose best answer\n",
    "agents.step() \n",
    "\n",
    "# Log results\n",
    "current_path = os.getcwd()\n",
    "log_path = os.path.join(os.path.dirname(current_path), \"logs\")\n",
    "agents.create_log(repo_path=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test results funciton\n",
    "\n",
    "idx_input = 8\n",
    "n_evaluations = 3\n",
    "n_agents = 5\n",
    "\n",
    "# Create agents\n",
    "agents = Agents(task=Game24, idx_input=idx_input, n_agents=n_agents, model=bot)\n",
    "\n",
    "# Run agents\n",
    "for i in range(agents.max_steps-1):\n",
    "    agents.step()\n",
    "    agents.evaluate(n=n_evaluations)\n",
    "    agents.resample()\n",
    "\n",
    "# Final step : Finish answers format + Choose best answer\n",
    "agents.step() \n",
    "\n",
    "print(\"\\n\\n\".join([\"\\n\".join(agent.steps) for agent in agents.agents]))\n",
    "print(f\"\\nResults : {agents.test_output()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "# set up logging\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from diskcache import Cache\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# TODO: Not sure if this is correct, I didn't know how else to handle the package paths\n",
    "import sys\n",
    "sys.path.append(os.getcwd()) # Project root!!\n",
    "\n",
    "from async_engine.cached_api import CachedOpenAIAPI\n",
    "from async_engine.round_robin_manager import AsyncRoundRobin\n",
    "from async_implementation.agents.gameof24 import GameOf24Agent\n",
    "from async_implementation.states.gameof24 import GameOf24State\n",
    "from utils import create_folder, email_notification\n",
    "from async_engine.batched_api import BatchingAPI\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batched API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bactched API\n",
    "\n",
    "# Cache setup\n",
    "assert os.path.exists(\n",
    "    \"./caches/\"), \"Please run the script from the root directory of the project. To make sure all caches are created correctly.\"\n",
    "cache = Cache(\"./caches/async_api_cache\", size_limit=int(2e10))\n",
    "\n",
    "# OpenAI API key setup\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "assert OPENAI_API_KEY is not None, \"Please set the OPENAI_API_KEY environment variable\"\n",
    "\n",
    "# API setup\n",
    "api_config = {\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"request_timeout\": 45,\n",
    "    \"model\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "\n",
    "\n",
    "#response = await api.uncached_request(messages, limiter, n=1)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Using 3 cached samples\n",
      "[1.002]\n"
     ]
    }
   ],
   "source": [
    "api = CachedOpenAIAPI(cache, api_config)\n",
    "\n",
    "# Limiter setup\n",
    "limiter = AsyncRoundRobin()\n",
    "N = 4\n",
    "for _ in range(N):\n",
    "    limiter.add_resource(data=OPENAI_API_KEY)\n",
    "\n",
    "batch_size = 3\n",
    "bapi = BatchingAPI(api, limiter, batch_size)\n",
    "print(api.used_count)\n",
    "\n",
    "state = GameOf24State(puzzle='1 1 4 6', current_state='2 5 6', steps=['1 + 4 = 5 (left: 2 5 6)'], randomness=121)\n",
    "\n",
    "puzzle_idx = 0\n",
    "agent_id = 0\n",
    "step = 0\n",
    "coroutines = []\n",
    "for _ in range(1):\n",
    "    coroutines.append(GameOf24Agent.evaluate(state, bapi, namespace=(puzzle_idx, f\"Agent: {agent_id}\", f\"Step : {step}\")))\n",
    "results = await asyncio.gather(*coroutines)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.18\n"
     ]
    }
   ],
   "source": [
    "## Accuracy computation\n",
    "\n",
    "import json \n",
    "\n",
    "with open(\"logs/same_experiment_logs/train-set_5agents_10steps_1k_60origin_0.6backtrack_linear-resampling.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "cost = results.pop(\"Cost\")\n",
    "# Accuracy computation\n",
    "n_success = 0\n",
    "for game in results.values():\n",
    "    if {\"r\":1} in game[\"Verifications\"]:\n",
    "        n_success += 1\n",
    "print(f\"Accuracy : {n_success/len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    api = CachedOpenAIAPI(cache, api_config)\n",
    "\n",
    "    # Limiter setup\n",
    "    limiter = AsyncRoundRobin()\n",
    "    N = 4\n",
    "    for _ in range(N):\n",
    "        limiter.add_resource(data=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "    # Setup batching API\n",
    "    batch_size = 2\n",
    "    bapi = BatchingAPI(api, limiter, batch_size)\n",
    "\n",
    "    state = GameOf24State(puzzle=\"6 6 8 12\", current_state=\"2 6 12\", steps=[\"8 - 6 = 2 (left: 2 6 12)\"], randomness=random.randint(0, 1000))\n",
    "\n",
    "    coroutines = []\n",
    "    for _ in range(2):\n",
    "        coroutines.append(GameOf24Agent.evaluate(state, bapi))\n",
    "    results = await asyncio.gather(*coroutines)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Futures : {bapi.futures}\")\n",
    "print(f\"Prompts : {bapi.prompts}\")\n",
    "print(f\"Batches processed : {bapi.num_batches_processed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crosswords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm keeping the same comments, etc everywhere, so that later it's easier to merge experiments.gameof24.py and experiments.crosswords.py (hydra?)\n",
    "\n",
    "import asyncio\n",
    "# set up logging\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from diskcache import Cache\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# TODO: Not sure if this is correct, I didn't know how else to handle the package paths\n",
    "import sys\n",
    "sys.path.append(os.getcwd()) # Project root!!\n",
    "\n",
    "from async_engine.cached_api import CachedOpenAIAPI\n",
    "from async_engine.round_robin_manager import AsyncRoundRobin\n",
    "from async_engine.batched_api import BatchingAPI\n",
    "from async_implementation.agents.crosswords import CrosswordsAgent\n",
    "from async_implementation.states.crosswords import CrosswordsState\n",
    "from async_implementation.resampling.resampler import Resampler\n",
    "from utils import create_folder, email_notification\n",
    "\n",
    "logger = logging.getLogger(\"experiments\")\n",
    "logger.setLevel(logging.DEBUG) # Order : debug < info < warning < error < critical\n",
    "log_folder = f\"logs/{datetime.now().date()}/{datetime.now().strftime('%H')}:00/crosswords/\" # Folder in which logs will be saved (organized daily)\n",
    "create_folder(log_folder)\n",
    "\n",
    "# you should use the same cache for every instance of CachedOpenAIAPI\n",
    "# that way we never pay for the same request twice\n",
    "assert os.path.exists(\n",
    "    \"./caches/\"), \"Please run the script from the root directory of the project. To make sure all caches are created correctly.\"\n",
    "cache = Cache(\"./caches/async_api_cache\", size_limit=int(2e10))\n",
    "\n",
    "# get OPENAI_API_KEY from env\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "assert OPENAI_API_KEY is not None, \"Please set the OPENAI_API_KEY environment variable\"\n",
    "\n",
    "api_config = {\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"request_timeout\": 45,\n",
    "    \"model\": \"gpt-3.5-turbo\"\n",
    "}\n",
    "\n",
    "api = CachedOpenAIAPI(cache, api_config)\n",
    "limiter = AsyncRoundRobin()\n",
    "# ToDo, this is a bit hacky. OpenAI allows multiple parallel requests per key, so we add the same key multiple times\n",
    "N = 4\n",
    "for _ in range(N):\n",
    "    limiter.add_resource(data=OPENAI_API_KEY)\n",
    "\n",
    "# Set up Crosswords puzzles\n",
    "path = \"data/datasets/mini0505.json\"\n",
    "with open(path, \"r\") as file:\n",
    "    dataset = json.load(file)\n",
    "\n",
    "api = BatchingAPI(api, limiter, batch_size=8, timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle_idx = 0\n",
    "\n",
    "data, board_gt = dataset[puzzle_idx] # Data is the list of clues, board_gt is the ground truth  board\n",
    "ans_gt = CrosswordsState.get_ans(board_gt) # Get the ground truth answers\n",
    "\n",
    "states = []\n",
    "for _ in range(1):\n",
    "    states.append(CrosswordsState(data=data, board_gt=board_gt, ans_gt=ans_gt, steps=[], randomness=random.randint(0, 1000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cached samples\n"
     ]
    }
   ],
   "source": [
    "new_state = await CrosswordsAgent.step(states[0], api, namespace = (-2, f\"Agent: {-1}\", f\"Step : {-1}\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
