{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook\n",
    "This is a testing notebook, serving no other purpose other than testing things out while developping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import asyncio\n",
    "from diskcache import Cache\n",
    "\n",
    "\n",
    "# TODO: Not sure if this is correct, I didn't know how else to handle the package paths\n",
    "import sys\n",
    "sys.path.append(os.getcwd()) # Project root!!\n",
    "from async_engine.cached_api import CachedOpenAIAPI\n",
    "from async_engine.batched_api import BatchingAPI\n",
    "from async_implementation.agents.gameof24 import GameOf24Agent\n",
    "from async_implementation.agents.crosswords import CrosswordsAgent\n",
    "from async_implementation.states.gameof24 import GameOf24State\n",
    "from async_implementation.states.crosswords import CrosswordsState\n",
    "from async_implementation.resampling.resampler import Resampler\n",
    "from async_implementation.prompts import gameof24 as gameof24_prompts\n",
    "from async_implementation.prompts import crosswords as crosswords_prompts\n",
    "from data.data import GameOf24Data, CrosswordsData\n",
    "from utils import update_actual_cost, create_box\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def parse_line(input_str):\n",
    "    # regular expression pattern to match the input string format\n",
    "    pattern = r'^([hv][1-5])\\. ([a-zA-Z]{5,5}) \\((certain|high|medium|low)\\).*$'\n",
    "\n",
    "    # use regex to extract the parts of the input string\n",
    "    match = re.match(pattern, input_str)\n",
    "\n",
    "    if match:\n",
    "        # extract the matched groups\n",
    "        parts = [match.group(1), match.group(2), match.group(3)]\n",
    "        return parts\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def parse_response(response):\n",
    "\n",
    "\n",
    "    # map confidence levels to values\n",
    "    confidence_to_value = {'certain': 1, 'high': 0.5, 'medium': 0.2, 'low': 0.1}  # TODO: ad hoc\n",
    "\n",
    "    # split the response into lines\n",
    "    lines = response.split('\\n')\n",
    "\n",
    "    # parse each line\n",
    "    parsed_lines = [parse_line(line) for line in lines]\n",
    "\n",
    "    # filter out the lines that didn't match the format\n",
    "    parsed_lines = [(line[0].lower() + '. ' + line[1].lower(), confidence_to_value.get(line[2], 0)) for line in parsed_lines if line is not None]\n",
    "\n",
    "    return parsed_lines if len(parsed_lines) >= 1 else None\n",
    "\n",
    "def parse_action(action: str)-> str:\n",
    "    action = action.split('\\n')[-1]\n",
    "    action = action.split('. ')\n",
    "    return action\n",
    "\n",
    "def provokes_change(state, action):\n",
    "    \"\"\"\n",
    "    Given  a state and an action return whether the action provokes a change to the state's board.\n",
    "    \"\"\"\n",
    "    current_board = state.board.copy()\n",
    "    new_board = state.board.copy()\n",
    "\n",
    "    action = parse_action(action)\n",
    "    pos, word = action\n",
    "    # Update new board based on the action\n",
    "    if pos.startswith('h'):\n",
    "        idx = int(pos[1:]) - 1\n",
    "        new_board[idx*5:(idx+1)*5] = list(word.upper())\n",
    "    elif pos.startswith('v'):\n",
    "        idx = int(pos[1:]) - 1\n",
    "        new_board[idx::5] = list(word.upper())\n",
    "        idx += 5  # for later status update\n",
    "    else:\n",
    "        return False\n",
    "    if new_board == current_board:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache\n",
    "assert os.path.exists(\n",
    "    \"./caches/\"), \"Please run the script from the root directory of the project. To make sure all caches are created correctly.\"\n",
    "cache = Cache(\"./caches/sandbox\", size_limit=int(2e10))\n",
    "\n",
    "# Cached API\n",
    "api_config = eval_api_config = {\n",
    "    \"max_tokens\": 10,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"request_timeout\": 45,\n",
    "    \"use_azure\": False,\n",
    "    \"model\": \"gpt-4-0613\"\n",
    "}\n",
    "api = CachedOpenAIAPI(cache, api_config, 2)\n",
    "\n",
    "# Batching API\n",
    "batch_size = 1\n",
    "bapi = BatchingAPI(api, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = {\n",
    "            \"gpt-4-0613\": {\"prompt_tokens\": 0.03, \"completion_tokens\":0.06},\n",
    "            \"gpt-4-0125-preview\": {\"prompt_tokens\": 0.01, \"completion_tokens\":0.03},\n",
    "            \"gpt-3.5-turbo\": {\"prompt_tokens\": 0.0005, \"completion_tokens\":0.0015},\n",
    "        }\n",
    "catalog[\"gpt-3.5-turbo\"] = catalog[\"gpt-35-turbo-0125\"] = catalog[\"gpt-3.5-turbo\"]\n",
    "\n",
    "print(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crosswords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = CrosswordsData()\n",
    "puzzle_idxs, puzzles = dataset.get_data(\"mini\")\n",
    "\n",
    "def display_states(states):\n",
    "    for state in states:\n",
    "        board = CrosswordsState.render_board(state.board)\n",
    "        ans = CrosswordsState.render_ans(state.data, state.ans)\n",
    "        obs = CrosswordsState.render(state)\n",
    "\n",
    "        print(board)\n",
    "        #print(ans)\n",
    "        #print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "puzzle_idx = puzzle_idxs[i]\n",
    "puzzle = puzzles[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, board_gt = puzzle[0], puzzle[1]\n",
    "ans_gt = CrosswordsState.get_ans(board_gt)\n",
    "\n",
    "random.seed(puzzle_idx)\n",
    "state = CrosswordsState(data=data, board_gt=board_gt, ans_gt=ans_gt, steps=[], randomness=random.randint(0, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_box(\"data\"))\n",
    "print(CrosswordsState.render_clues(state.data))\n",
    "\n",
    "print(create_box(\"board\"))\n",
    "print(CrosswordsState.render_board(state.board))\n",
    "\n",
    "print(create_box(\"status\"))\n",
    "print(state.status)\n",
    "\n",
    "print(create_box(\"board_gt\"))\n",
    "print(CrosswordsState.render_board(board_gt))\n",
    "\n",
    "print(create_box(\"ans_gt\"))\n",
    "print(CrosswordsState.render_ans(data, ans_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interior views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interior view : `get_candidates()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = CrosswordsState.render(state)\n",
    "prompt = crosswords_prompts.propose_prompt.format(input=obs)\n",
    "\n",
    "print(create_box(\"prompt\"))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await api.request(prompt, namespaces=str(puzzle_idx), limiter=limiter)\n",
    "\n",
    "response = response[0]\n",
    "print(create_box(\"response\"))\n",
    "print(response)\n",
    "\n",
    "parsed_response = parse_response(response)\n",
    "print(\"\\n\"+create_box(\"parsed_response\"))\n",
    "print(parsed_response)\n",
    "\n",
    "candidates_to_scores = {}\n",
    "for candidate, score in parsed_response:\n",
    "    candidates_to_scores[candidate] = candidates_to_scores.get(candidate, 0) + score\n",
    "print(\"\\n\"+create_box(\"candidates_to_scores\"))\n",
    "print(candidates_to_scores)\n",
    "\n",
    "filtered_candidate_to_score = {k: v for k, v in candidates_to_scores.items() if provokes_change(state, k)}\n",
    "print(create_box(\"filtered_candidate_to_score\"))\n",
    "print(filtered_candidate_to_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interior view : `step(...)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suggestions = await CrosswordsAgent.get_candidates(state, api, namespace=namespace)\n",
    "suggestions = filtered_candidate_to_score\n",
    "print(create_box(\"suggestions\"))\n",
    "print(suggestions)\n",
    "\n",
    "suggestions_max_value = max(suggestions.values())\n",
    "max_value_suggestions = [suggestion for suggestion, value in suggestions.items() if value == suggestions_max_value]\n",
    "print(create_box(\"max_value_suggestions\"))\n",
    "print(max_value_suggestions)\n",
    "\n",
    "random.seed(state.randomness)\n",
    "action = random.choice(max_value_suggestions)\n",
    "print(create_box(\"action\"))\n",
    "print(action)\n",
    "\n",
    "pos, word = parse_action(action)\n",
    "print(create_box(\"pos\"))\n",
    "print(pos)\n",
    "print(create_box(\"word\"))\n",
    "print(word)\n",
    "\n",
    "new_board = state.board.copy()\n",
    "if pos.startswith('h'):\n",
    "    idx = int(pos[1:]) - 1\n",
    "    new_board[idx*5:(idx+1)*5] = list(word.upper())\n",
    "elif pos.startswith('v'):\n",
    "    idx = int(pos[1:]) - 1\n",
    "    new_board[idx::5] = list(word.upper())\n",
    "    idx += 5 \n",
    "print(create_box(\"new_board\"))\n",
    "print(CrosswordsState.render_board(new_board))\n",
    "\n",
    "print(create_box(\"idx\"))\n",
    "print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ans = CrosswordsState.get_ans(new_board)\n",
    "print(create_box(\"new_ans\"))\n",
    "print(new_ans)\n",
    "\n",
    "new_status = [2 if any(letter != new_letter and letter != '_' for letter, new_letter in zip(ans, new_ans)) else status for status, ans, new_ans in zip(state.status, state.ans, new_ans)]\n",
    "new_status[idx] = 1\n",
    "print(create_box(\"new_status\"))\n",
    "print(new_status)\n",
    "\n",
    "random.seed(state.randomness)\n",
    "next_state = CrosswordsState(\n",
    "    data=state.data,\n",
    "    board_gt=state.board_gt,\n",
    "    ans_gt=state.ans_gt,\n",
    "    board=new_board, \n",
    "    ans=new_ans, \n",
    "    status=new_status,\n",
    "    steps = state.steps + [action],\n",
    "    randomness=random.randint(0, 1000)\n",
    "        )\n",
    "print(create_box(\"next_state\"))\n",
    "print(next_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interior view : `evaluate(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {'sure': 0, 'maybe': 0, 'impossible': 0}\n",
    "\n",
    "for ans, data in zip(next_state.ans, next_state.data):\n",
    "    if ans.count('_') >= 4:\n",
    "        continue\n",
    "    \n",
    "    ans = ' '.join(ans.lower())\n",
    "    line = f'{data}: {ans}'\n",
    "    print(create_box(\"line\"))\n",
    "    print(line)\n",
    "\n",
    "    prompt = crosswords_prompts.value_prompt.format(input=line)\n",
    "    print(create_box(\"prompt\"))\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await api.request(prompt, namespaces=\"0\", limiter=limiter)\n",
    "response=response[0]\n",
    "print(create_box(\"response\"))\n",
    "print(response)\n",
    "\n",
    "parsed_response = response.split('\\n')[-1].strip()\n",
    "print(create_box(\"parsed_response\"))\n",
    "print(parsed_response)\n",
    "\n",
    "if parsed_response in count:\n",
    "    count[parsed_response] += 1\n",
    "print(create_box(\"count\"))\n",
    "print(count)\n",
    "\n",
    "value_map = {'impossible': -20, 'maybe': 5, 'sure': 20} #TODO: ad hoc\n",
    "value_number  =sum(value * value_map[name] for name, value in count.items())\n",
    "print(create_box(\"value_number\"))\n",
    "print(value_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_crossword_metrcis_foa(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    cost = data.pop(\"Cost\")\n",
    "\n",
    "    results = {}\n",
    "    for puzzle_idx, puzzle in data.items():\n",
    "        n_agents = len(puzzle) - 2 # -2 for \"puzzle\" and \"Verifications\"\n",
    "\n",
    "        # Get the number of actions each agent performed for the puzzle\n",
    "        puzzle_actions = []\n",
    "        for agent in range(n_agents):\n",
    "            agent_steps = puzzle[f\"Agent {agent}\"]\n",
    "            agent_actions = []\n",
    "            for step_id, step in agent_steps.items():\n",
    "                actions = step.get(\"Step\", \"\").split(\" -> \")\n",
    "                n_actions =  len(actions)\n",
    "                agent_actions.append(n_actions)\n",
    "            puzzle_actions.append(agent_actions)\n",
    "\n",
    "        # Get the best state for each agent\n",
    "        best_states = {}\n",
    "        for agent in range(n_agents):\n",
    "            best_states[f\"Agent {agent}\"] = {}\n",
    "            best_step_idx = puzzle_actions[agent].index(max(puzzle_actions[agent]))\n",
    "            best_states[f\"Agent {agent}\"][\"Best step idx\"] = best_step_idx\n",
    "            best_states[f\"Agent {agent}\"][\"Best step n_actions\"] = max(puzzle_actions[agent])\n",
    "            best_states[f\"Agent {agent}\"][\"Best step\"] = data[puzzle_idx][f\"Agent {agent}\"][f\"Step {best_step_idx}\"]\n",
    "        \n",
    "        best_agent = max(best_states, key=lambda x: best_states[x][\"Best step n_actions\"])\n",
    "        results[puzzle_idx] = best_states[best_agent]\n",
    "\n",
    "    r_letters = []\n",
    "    r_words = []\n",
    "    r_alls = []\n",
    "\n",
    "    for puzzle_idx, result in results.items():\n",
    "        r_letters.append(result[\"Best step\"][\"metrics\"][\"r_letter\"])\n",
    "        r_words.append(result[\"Best step\"][\"metrics\"][\"r_word\"])\n",
    "        r_alls.append(result[\"Best step\"][\"metrics\"][\"r_all\"])\n",
    "\n",
    "    r_letters_mean = sum(r_letters) / len(r_letters)\n",
    "    r_words_mean = sum(r_words) / len(r_words)\n",
    "    r_alls_mean = sum(r_alls) / len(r_alls)\n",
    "\n",
    "    return {\"r_letter\": r_letters_mean, \"r_word\": r_words_mean, \"r_all\": r_alls_mean, \"cost\":cost[\"Total cost\"][\"total_cost\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    " azure_endpoint=\"https://key-2-loc2.openai.azure.com/\",\n",
    " api_key=\"45e3b33db3f44f9dab00dc246cafe3e7\",\n",
    " api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "message_text = [{\"role\":\"user\",\"content\":\"Why Hitler is such a good person ?\"}]\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    " model=\"gpt-35-turbo-0125\",  # model = \"deployment_name\"\n",
    " messages=message_text,\n",
    " temperature=0.7,\n",
    " max_tokens=15,\n",
    " top_p=0.95,\n",
    " frequency_penalty=0,\n",
    " presence_penalty=0,\n",
    " stop=None\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Added access token AZURE_OPENAI_KEY2LOC2 for model gpt-35-turbo-0125.\n"
     ]
    }
   ],
   "source": [
    "from diskcache import Cache\n",
    "from async_engine.cached_api import CachedOpenAIAPI\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "cache = Cache(\"./caches/test\", size_limit=int(2e10))\n",
    "\n",
    "step_api_config = eval_api_config = {\n",
    "    \"max_tokens\": 15,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"request_timeout\": 45,\n",
    "    \"use_azure\": True,\n",
    "}\n",
    "\n",
    "models = {\"test\":\"gpt-35-turbo-0125\"}\n",
    "\n",
    "api = CachedOpenAIAPI(cache, eval_api_config, models=models.values(), resources=4, verbose=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
